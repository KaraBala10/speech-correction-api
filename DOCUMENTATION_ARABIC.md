# ÙˆØ«Ø§Ø¦Ù‚ Ù…Ø´Ø±ÙˆØ¹ ØªØ·Ø¨ÙŠÙ‚ ØªØµØ­ÙŠØ­ Ø§Ù„Ù†Ø·Ù‚ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ

## Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† ØªØ·Ø¨ÙŠÙ‚ ÙˆÙŠØ¨ Ù…ØªÙƒØ§Ù…Ù„ Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØªØµØ­ÙŠØ­ Ø§Ù„Ù†Ø·Ù‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. ÙŠØªÙƒÙˆÙ† Ù…Ù† ÙˆØ§Ø¬Ù‡Ø© Ø£Ù…Ø§Ù…ÙŠØ© ØªÙØ§Ø¹Ù„ÙŠØ© (Frontend) ÙˆÙˆØ§Ø¬Ù‡Ø© Ø®Ù„ÙÙŠØ© (Backend) ØªØ¯Ø¹Ù… Ø§Ù„Ù„ØºØªÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.

## Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ù„Ù„Ù…Ø´Ø±ÙˆØ¹

### 1. Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© (Architecture)
- **Ù†Ù…Ø· Ø§Ù„Ø¨Ù†ÙŠØ©**: Microservices Architecture
- **Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©**: Django REST Framework + React.js
- **Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: MySQL 8.0
- **Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª**: Redis
- **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ©**: Celery
- **Ø§Ù„Ø­Ø§ÙˆÙŠØ§Øª**: Docker & Docker Compose

### 2. Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

#### Ø£) Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø®Ù„ÙÙŠØ© (Backend)
- **Ø§Ù„Ø¥Ø·Ø§Ø±**: Django 5.1.5
- **ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª**: Django REST Framework
- **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª**: OpenAI Whisper
- **Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†**: Ù†Ø¸Ø§Ù… Ù…ØµØ§Ø¯Ù‚Ø© Ù…Ø®ØµØµ
- **Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: MySQL Ù…Ø¹ Django ORM

#### Ø¨) Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© (Frontend)
- **Ø§Ù„Ø¥Ø·Ø§Ø±**: React 19.0.0
- **Ø§Ù„ØªÙˆØ¬ÙŠÙ‡**: React Router DOM
- **Ø§Ù„ØªØµÙ…ÙŠÙ…**: Tailwind CSS
- **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª**: WaveSurfer.js
- **Ø§Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª**: Lucide React

## Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„ÙˆØ¸Ø§Ø¦Ù

### 1. Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†

#### Ø£) Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ§Ù„ØªØ­Ù‚Ù‚
- **Ø§Ù„ØªØ³Ø¬ÙŠÙ„**: Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø³Ø§Ø¨ Ø¬Ø¯ÙŠØ¯ Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
- **Ø§Ù„ØªØ­Ù‚Ù‚**: Ø¥Ø±Ø³Ø§Ù„ Ø±Ù…Ø² ØªØ­Ù‚Ù‚ Ù…ÙƒÙˆÙ† Ù…Ù† 8 Ø£Ø±Ù‚Ø§Ù…
- **Ø§Ù„Ø£Ù…Ø§Ù†**: Ø­Ù…Ø§ÙŠØ© Ø¶Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø© (Rate Limiting)
- **Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ø±ÙŠØ¯**: Ø¥Ø±Ø³Ø§Ù„ Ø±Ù…Ø² ØªØ­Ù‚Ù‚ Ø¹Ø¨Ø± SMTP

#### Ø¨) ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ù„Ø®Ø±ÙˆØ¬
- **Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©**: Ù†Ø¸Ø§Ù… ØªÙˆÙƒÙ† (Token-based Authentication)
- **Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø§Øª**: Django Sessions
- **Ø§Ù„Ø£Ù…Ø§Ù†**: ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙˆØ±

#### Ø¬) Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø´Ø®ØµÙŠ
- **Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ©**: Ø§Ù„Ø§Ø³Ù…ØŒ Ø§Ù„Ø¨Ù„Ø¯ØŒ Ø§Ù„Ø³ÙŠØ±Ø© Ø§Ù„Ø°Ø§ØªÙŠØ©
- **Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø´Ø®ØµÙŠØ©**: Ø±ÙØ¹ ÙˆØªØ®Ø²ÙŠÙ† Ø§Ù„ØµÙˆØ±
- **Ø§Ù„ØªØ­Ø¯ÙŠØ«**: ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ©

### 2. Ù†Ø¸Ø§Ù… ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù†Ø·Ù‚

#### Ø£) Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù„ØºØ§Øª
- **Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©**: Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
- **Ø§Ù„Ù…Ø±ÙˆÙ†Ø©**: Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø¥Ø¶Ø§ÙØ© Ù„ØºØ§Øª Ø¬Ø¯ÙŠØ¯Ø©
- **Ø§Ù„Ø­Ø§Ù„Ø©**: ØªÙØ¹ÙŠÙ„/Ø¥Ù„ØºØ§Ø¡ ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù„ØºØ§Øª

#### Ø¨) Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø±ÙˆÙ
- **Ø§Ù„Ø­Ø±ÙˆÙ**: ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø­Ø±ÙˆÙ Ù…Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø©
- **Ø§Ù„ÙˆØ³Ø§Ø¦Ø·**: Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©
- **Ø§Ù„ØªØµÙ†ÙŠÙ**: Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„ØªØ±ØªÙŠØ¨
- **Ø§Ù„Ø­Ø§Ù„Ø©**: ØªÙØ¹ÙŠÙ„/Ø¥Ù„ØºØ§Ø¡ ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø­Ø±ÙˆÙ

#### Ø¬) Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
- **Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª**: Ù…Ø³ØªÙˆÙŠØ§Øª Ù…ØªØ¯Ø±Ø¬Ø© Ù„ÙƒÙ„ Ø­Ø±Ù
- **Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©**: ÙƒÙ„Ù…Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
- **Ø§Ù„ØµØ¹ÙˆØ¨Ø©**: Ø³Ù‡ÙˆÙ„Ø©ØŒ Ù…ØªÙˆØ³Ø·Ø©ØŒ ØµØ¹Ø¨Ø©
- **Ø§Ù„ÙˆØ³Ø§Ø¦Ø·**: Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©

### 3. Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø·Ù‚

#### Ø£) ØªÙ‚Ù†ÙŠØ© Whisper
- **Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…**: OpenAI Whisper Tiny (Ø£ØµØºØ± ÙˆØ£Ø³Ø±Ø¹ Ù†Ù…ÙˆØ°Ø¬)
- **Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©**: Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù…Ø¹ Ø¯Ø¹Ù… ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ù„ØºØ©
- **Ø§Ù„Ø¯Ù‚Ø©**: 99%+ Ø¯Ù‚Ø© ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
- **Ø§Ù„ØªØ®Ø²ÙŠÙ†**: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙˆØªØ®Ø²ÙŠÙ†Ù‡ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Singleton Pattern)
- **Ø§Ù„Ø­Ø¬Ù…**: ~39MB Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ù…Ù„

**Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹:**
```python
# ÙÙŠ Ù…Ù„Ù views.py - ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
MODEL_DIR = "models"
MODEL_SIZE = "tiny"

_model = None

def get_model():
    global _model
    if _model is None:
        _model = whisper.load_model(MODEL_SIZE, download_root=MODEL_DIR)
    return _model

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„
def transcribe_audio(audio_file):
    model = get_model()
    result = model.transcribe(audio_file, language="ar", fp16=False)
    return result["text"]
```

**Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ù†Ù…Ø§Ø°Ø¬ Ø£Ø®Ø±Ù‰:**
- **Whisper Tiny**: 39MBØŒ Ø³Ø±ÙŠØ¹ØŒ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
- **Whisper Base**: 74MBØŒ Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰ Ù‚Ù„ÙŠÙ„Ø§Ù‹
- **Whisper Small**: 244MBØŒ Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
- **Whisper Medium**: 769MBØŒ Ø¯Ù‚Ø© Ù…Ù…ØªØ§Ø²Ø©
- **Whisper Large**: 1550MBØŒ Ø£Ø¹Ù„Ù‰ Ø¯Ù‚Ø©

#### Ø¨) Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
- **Ø§Ù„ØªØ³Ø¬ÙŠÙ„**: ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ù…ØªØµÙØ­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… MediaRecorder API
- **Ø§Ù„ØªØ­ÙˆÙŠÙ„**: ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ WAV Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… FFmpeg
- **Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ±**: 16kHz Sample Rate, Mono Channel, 16-bit PCM
- **Ø§Ù„Ø£Ø¯ÙˆØ§Øª**: FFmpeg Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØªØŒ WaveSurfer.js Ù„Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¨ØµØ±ÙŠ

**Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª ÙÙŠ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹:**
```python
# ÙÙŠ Ù…Ù„Ù views.py - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
@csrf_exempt
def transcribe(request):
    if "audio" not in request.FILES:
        return JsonResponse({"error": "No audio file provided"}, status=400)

    audio_file = request.FILES.get("audio")
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù…ØªØ¯Ø§Ø¯ Ø§Ù„Ù…Ù„Ù
    ext = os.path.splitext(audio_file.name)[-1]
    if not ext:
        ext = mimetypes.guess_extension(audio_file.content_type) or ".ogg"

    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
    with tempfile.NamedTemporaryFile(suffix=ext, delete=False) as temp_in:
        for chunk in audio_file.chunks():
            temp_in.write(chunk)
        temp_in.flush()

    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… FFmpeg
    fixed_wav = tempfile.NamedTemporaryFile(suffix=".wav", delete=False).name
    try:
        proc = subprocess.run([
            "ffmpeg", "-y", "-i", temp_in.name,
            "-ar", "16000",  # Sample rate 16kHz
            "-ac", "1",      # Mono channel
            "-c:a", "pcm_s16le",  # 16-bit PCM
            fixed_wav,
        ], capture_output=True, text=True)
        
        if proc.returncode != 0:
            return JsonResponse({"error": f"ffmpeg failed: {proc.stderr}"}, status=500)

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø·Ù‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper
        model = get_model()
        result = model.transcribe(fixed_wav, language="ar", fp16=False)
        reference = result["text"]

    except Exception as e:
        return JsonResponse({"error": str(e)}, status=500)
    finally:
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
        os.remove(temp_in.name)
        os.remove(fixed_wav)
```

**Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©:**
```javascript
// ÙÙŠ Ù…Ù„Ù voicePopup.jsx - ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª
const startRecording = async () => {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…
        const mimeType = MediaRecorder.isTypeSupported("audio/webm;codecs=opus")
            ? "audio/webm;codecs=opus"
            : "audio/ogg;codecs=opus";

        const recorder = new MediaRecorder(stream, { mimeType });
        setAudioChunks([]);

        recorder.ondataavailable = (e) => {
            if (e.data && e.data.size > 0) {
                setAudioChunks((prev) => [...prev, e.data]);
            }
        };

        recorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: mimeType });
            const ext = mimeType.includes("webm") ? "webm" : "ogg";
            
            // Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª Ù„Ù„ØªØ­Ù„ÙŠÙ„
            const formData = new FormData();
            formData.append("audio", audioBlob, `recorded_audio.${ext}`);
            formData.append("target_word", targetWord);
            formData.append("target_char", targetLetter);

            const response = await fetch("http://localhost:9999/api/transcribe/", {
                method: "POST",
                body: formData,
            });
            const data = await response.json();
            setLocalResult(data);
        };

        recorder.start();
        setIsListening(true);
        setMediaRecorder(recorder);
    } catch (err) {
        console.error("ÙØ´Ù„ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù…Ø§ÙŠÙƒØ±ÙˆÙÙˆÙ†:", err);
    }
};
```

#### Ø¬) Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
```python
# Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„Ù…Ø­Ø³Ù†Ø©
def analyze_pronunciation_advanced(target_word, reference, target_char):
    """
    Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø·Ù‚ Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø®ØµÙˆØµÙŠØ§Øª Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    """
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    target_word = target_word.strip()
    reference = reference.strip()
    
    # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    matches = sum(1 for a, b in zip(reference, target_word) if a == b)
    max_len = max(len(reference), len(target_word))
    percentage = (matches / max_len) * 100 if max_len > 0 else 0
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
    if target_char not in target_word:
        return {
            "test_passed": False,
            "message": "Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©",
            "similarity_percentage": 0,
            "target_word": target_word,
            "reference": reference
        }
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø·Ù‚ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
    if target_char not in reference:
        return {
            "test_passed": False,
            "message": "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù",
            "similarity_percentage": percentage,
            "target_word": target_word,
            "reference": reference
        }
    
    # ØªØ­Ù„ÙŠÙ„ Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
    target_positions = [i for i, char in enumerate(target_word) if char == target_char]
    reference_positions = [i for i, char in enumerate(reference) if char == target_char]
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø·Ù‚ Ø§Ù„Ø­Ø±Ù ÙÙŠ Ø¬Ù…ÙŠØ¹ Ù…ÙˆØ§Ø¶Ø¹Ù‡
    for target_pos in target_positions:
        if target_pos >= len(reference) or reference[target_pos] != target_char:
            return {
                "test_passed": False,
                "message": "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù",
                "similarity_percentage": percentage,
                "target_word": target_word,
                "reference": reference
            }
    
    # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    if percentage < 60:
        return {
            "test_passed": False,
            "message": "Ù„Ù‚Ø¯ Ù†Ø·Ù‚Øª Ø§ØºÙ„Ø¨ Ø§Ù„Ø§Ø­Ø±Ù Ø¨Ø´ÙƒÙ„ Ø®Ø§Ø·Ø¦ØŒ Ø§Ø³ØªÙ…Ø¹ Ù…Ø±Ø© Ø§Ø®Ø±Ù‰ Ù„Ù„ØµÙˆØª Ø§Ù„Ù…Ø³Ø¬Ù„ Ø«Ù… Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø§Ø®Ø±Ù‰",
            "similarity_percentage": percentage,
            "target_word": target_word,
            "reference": reference
        }
    else:
        return {
            "test_passed": True,
            "message": "Ù…Ø¨Ø§Ø±ÙƒØŒ Ù„Ù‚Ø¯ Ø§Ø¬ØªØ²Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­",
            "similarity_percentage": percentage,
            "target_word": target_word,
            "reference": reference
        }
```

**Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©:**
```python
# Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ù†Ø·Ù‚ Ø§Ù„Ø­Ø±Ù "Ø£"
target_word = "Ø£Ø±Ù†Ø¨"
user_pronunciation = "Ø£Ø±Ù†Ø¨"  # Ù†Ø·Ù‚ ØµØ­ÙŠØ­
target_char = "Ø£"

result = analyze_pronunciation_advanced(target_word, user_pronunciation, target_char)
# Ø§Ù„Ù†ØªÙŠØ¬Ø©: {"test_passed": True, "similarity_percentage": 100.0, ...}

# Ù…Ø«Ø§Ù„ Ù„Ù†Ø·Ù‚ Ø®Ø§Ø·Ø¦
user_pronunciation = "Ø±Ù†Ø¨"  # Ø­Ø°Ù Ø§Ù„Ø­Ø±Ù "Ø£"
result = analyze_pronunciation_advanced(target_word, user_pronunciation, target_char)
# Ø§Ù„Ù†ØªÙŠØ¬Ø©: {"test_passed": False, "message": "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù", ...}
```

#### Ø¯) ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ

**1. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡:**
```python
def preprocess_audio(audio_file):
    """
    Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ù„Ù„ØµÙˆØª Ù„ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
    """
    # ØªØ·Ø¨ÙŠÙ‚ ÙÙ„ØªØ± Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
    # ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª
    # ØªØ·Ø¨ÙŠØ¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª
    pass
```

**2. Ø¯Ø¹Ù… Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©:**
```python
def detect_dialect(audio_file):
    """
    ÙƒØ´Ù Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ù†Ø·Ù‚
    """
    # ØªØ­Ù„ÙŠÙ„ Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù†Ø·Ù‚
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„Ù‡Ø¬Ø© (Ù…ØµØ±ÙŠØ©ØŒ Ø®Ù„ÙŠØ¬ÙŠØ©ØŒ Ù…ØºØ±Ø¨ÙŠØ©ØŒ Ø¥Ù„Ø®)
    # ØªØ·Ø¨ÙŠÙ‚ Ù‚ÙˆØ§Ø¹Ø¯ Ø®Ø§ØµØ© Ø¨ÙƒÙ„ Ù„Ù‡Ø¬Ø©
    pass
```

**3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø¨Ø±Ø© ÙˆØ§Ù„Ø³Ø±Ø¹Ø©:**
```python
def analyze_prosody(audio_file):
    """
    ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø¨Ø±Ø© ÙˆØ§Ù„Ø³Ø±Ø¹Ø© ÙˆØ§Ù„Ø¥ÙŠÙ‚Ø§Ø¹
    """
    # ØªØ­Ù„ÙŠÙ„ Ø³Ø±Ø¹Ø© Ø§Ù„Ù†Ø·Ù‚
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø¨Ø±Ø©
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹
    pass
```

### 4. Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙˆØ§Ù„ØªØ¯Ø±ÙŠØ¨Ø§Øª

#### Ø£) Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª
- **Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª**: ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ù„ØºÙˆÙŠØ©
- **Ø§Ù„ÙˆØµÙ**: ÙˆØµÙ ØªÙØµÙŠÙ„ÙŠ Ù„ÙƒÙ„ Ù…Ù‡Ø§Ø±Ø©
- **Ø§Ù„ØªØ±ØªÙŠØ¨**: ØªØ±ØªÙŠØ¨ Ù…Ù†Ø·Ù‚ÙŠ Ù„Ù„Ù…Ù‡Ø§Ø±Ø§Øª

#### Ø¨) Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
- **Ø§Ù„Ø£Ø³Ø¦Ù„Ø©**: Ø£Ø³Ø¦Ù„Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª
- **Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª**: Ø¥Ø¬Ø§Ø¨Ø§Øª ØµØ­ÙŠØ­Ø© ÙˆØ®Ø§Ø·Ø¦Ø©
- **Ø§Ù„ØªØµÙ†ÙŠÙ**: Ø­Ø³Ø¨ Ø§Ù„Ù…Ù‡Ø§Ø±Ø© ÙˆØ§Ù„ØµØ¹ÙˆØ¨Ø©
- **Ø§Ù„ØªÙ‚ÙŠÙŠÙ…**: ØªÙ‚ÙŠÙŠÙ… ÙÙˆØ±ÙŠ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª

### 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©

#### Ø£) Ù†Ø¸Ø§Ù… Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…ØªÙ‚Ø¯Ù… (Design System)

**1. Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©:**
```css
/* Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù†ÙŠÙˆÙ† */
:root {
  --neon-blue: #00d4ff;
  --neon-purple: #a855f7;
  --neon-green: #00ff88;
  --neon-pink: #ff0080;
  --neon-cyan: #00ffff;
  --neon-orange: #ff6b35;
  
  /* Ø§Ù„ØªØ¯Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© */
  --gradient-cyber: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  --gradient-neon: linear-gradient(45deg, #00d4ff, #a855f7, #00ff88);
  --gradient-hologram: linear-gradient(45deg, rgba(0, 212, 255, 0.1), rgba(168, 85, 247, 0.1), rgba(0, 255, 136, 0.1));
  --gradient-dark: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 50%, #16213e 100%);
}
```

**2. Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø²Ø±Ø§Ø± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©:**
```css
/* Ø²Ø± Ø£Ø³Ø§Ø³ÙŠ Ù…Ø¹ ØªØ£Ø«ÙŠØ±Ø§Øª Ù†ÙŠÙˆÙ† */
.btn-primary {
  background: var(--gradient-neon);
  color: white;
  font-weight: 600;
  padding: 0.875rem 2rem;
  border-radius: 50px;
  border: 2px solid transparent;
  box-shadow: 
    0 0 20px rgba(0, 212, 255, 0.3),
    0 0 40px rgba(0, 212, 255, 0.1),
    inset 0 0 20px rgba(255, 255, 255, 0.1);
  transition: all 0.4s var(--ease-elastic);
  transform: translateY(0);
  position: relative;
  overflow: hidden;
}

.btn-primary:hover {
  box-shadow: 
    0 0 30px rgba(0, 212, 255, 0.5),
    0 0 60px rgba(0, 212, 255, 0.2),
    inset 0 0 30px rgba(255, 255, 255, 0.2);
  transform: translateY(-3px) scale(1.05);
  border-color: var(--neon-blue);
}
```

**3. ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø¨Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ø²Ø¬Ø§Ø¬ÙŠØ©:**
```css
/* Ø¨Ø·Ø§Ù‚Ø© Ù…Ø¹ ØªØ£Ø«ÙŠØ± Ø²Ø¬Ø§Ø¬ÙŠ */
.card-gradient {
  background: var(--gradient-hologram);
  backdrop-filter: blur(20px);
  border-radius: 20px;
  border: 1px solid rgba(0, 212, 255, 0.2);
  box-shadow: 
    0 8px 32px rgba(0, 0, 0, 0.3),
    0 0 20px rgba(0, 212, 255, 0.1),
    inset 0 1px 0 rgba(255, 255, 255, 0.1);
  transition: all 0.4s var(--ease-elastic);
  transform: translateY(0);
  position: relative;
  overflow: hidden;
}
```

#### Ø¨) Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©

**1. Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ†Ù‚Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…:**
```jsx
// Ù…ÙƒÙˆÙ† Navbar Ù…Ø¹ ØªØ£Ø«ÙŠØ±Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
export default function Navbar() {
  const [scrolled, setScrolled] = useState(false);
  const [token, setToken] = useState(null);
  const [profileData, setProfileData] = useState(null);
  const [showProfileDropdown, setShowProfileDropdown] = useState(false);

  // ØªØ£Ø«ÙŠØ± Ø§Ù„ØªÙ…Ø±ÙŠØ±
  useEffect(() => {
    const handleScroll = () => {
      const isScrolled = window.scrollY > 10;
      setScrolled(isScrolled);
    };
    window.addEventListener("scroll", handleScroll);
    return () => window.removeEventListener("scroll", handleScroll);
  }, []);

  return (
    <nav className={`fixed top-0 left-0 w-full z-50 transition-all duration-500 ease-out ${
      scrolled
        ? "bg-cyber-950/95 backdrop-blur-xl shadow-neon-blue border-b border-neon-blue/20"
        : "bg-cyber-950/80 backdrop-blur-lg"
    }`}>
      {/* Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø´Ø±ÙŠØ· */}
    </nav>
  );
}
```

**2. ØµÙØ­Ø© Ø§Ù„Ø­Ø±ÙˆÙ Ù„Ù„Ø£Ø·ÙØ§Ù„:**
```jsx
// ØµÙØ­Ø© ØªØ¹Ù„Ù… Ø§Ù„Ø­Ø±ÙˆÙ Ù…Ø¹ ØªØªØ¨Ø¹ Ø§Ù„ØªÙ‚Ø¯Ù…
export default function ChildPage() {
  const [letters, setLetters] = useState([]);
  const [completedLetters, setCompletedLetters] = useState([]);

  useEffect(() => {
    fetch(`http://localhost:9999/api/${lan}/letters/`)
      .then((res) => res.json())
      .then((data) => {
        setLetters(data.letters);
        // Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©
        const passed = JSON.parse(localStorage.getItem("passedLevels")) || [];
        const counts = passed.reduce((acc, { letter }) => {
          acc[letter] = (acc[letter] || 0) + 1;
          return acc;
        }, {});
        const completed = Object.keys(counts).filter(
          (letter) => counts[letter] === 5
        );
        setCompletedLetters(completed);
      });
  }, []);

  return (
    <div className="relative min-h-screen bg-gradient-dark text-white overflow-hidden">
      {/* Ø®Ù„ÙÙŠØ© Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠØ© */}
      <div className="fixed inset-0 cyber-grid opacity-10 z-[-2]"></div>
      
      {/* ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø¬Ø²ÙŠØ¦Ø§Øª */}
      <div className="fixed inset-0 particles z-[-1]"></div>
      
      {/* Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¹Ø§Ø¦Ù…Ø© */}
      <div className="absolute top-20 left-20 w-20 h-20 bg-neon-blue rounded-full opacity-20 animate-float"></div>
      
      {/* Ø´Ø¨ÙƒØ© Ø§Ù„Ø­Ø±ÙˆÙ */}
      <div className="grid grid-cols-2 sm:grid-cols-3 md:grid-cols-4 lg:grid-cols-6 gap-6">
        {letters.map((elem, index) => {
          const isCompleted = completedLetters.includes(elem.letter);
          return (
            <button
              key={index}
              onClick={() => navigate(`/FiveLevelPage/${lan}/${elem.letter}`)}
              className={`group relative card-gradient p-6 rounded-2xl shadow-glass border transition-all duration-300 hover-lift ${
                isCompleted ? "border-neon-green/30" : "border-cyber-700/50"
              } backdrop-blur-md animate-fade-in-up`}
              style={{ animationDelay: `${index * 50}ms` }}
            >
              {/* Ø´Ø§Ø±Ø© Ø§Ù„Ø¥ÙƒÙ…Ø§Ù„ */}
              {isCompleted && (
                <div className="absolute -top-1 -right-1 w-8 h-8 bg-gradient-neon rounded-full flex items-center justify-center text-cyber-950 neon-glow">
                  <Check className="w-16 h-16 text-green-500" />
                </div>
              )}
              
              <div className="relative z-10 flex flex-col items-center">
                <div className={`text-5xl font-extrabold mb-4 ${
                  isCompleted ? "text-white" : "text-cyber-200"
                }`}>
                  {elem.letter}
                </div>
              </div>
            </button>
          );
        })}
      </div>
    </div>
  );
}
```

**3. ØµÙØ­Ø© Ø§Ù„Ø¨Ø§Ù„ØºÙŠÙ† ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª:**
```jsx
// ØµÙØ­Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù„Ù„Ø¨Ø§Ù„ØºÙŠÙ†
export default function QuizPage() {
  const [isCorrect, setIsCorrect] = useState(null);
  const [selectedOption, setSelectedOption] = useState(null);
  const [quesNum, setQuesNum] = useState(0);
  const [result, setResult] = useState(0);
  
  const handleAnswer = (option) => {
    setSelectedOption(option);
    setIsCorrect(option === quiz.correct_answer);
    if (option === quiz.correct_answer) {
      setResult(result + 1);
    }
  };

  return (
    <div className="relative min-h-screen bg-gradient-dark text-white overflow-hidden">
      {/* Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù… */}
      <div className="mb-8">
        <div className="flex justify-between items-center mb-2">
          <span className="text-cyber-300 text-sm">Progress</span>
          <span className="text-neon-blue font-semibold">
            {quesNum + 1}/{filteredQuizzes.length}
          </span>
        </div>
        <div className="w-full bg-cyber-800 rounded-full h-2 overflow-hidden">
          <div
            className="h-full bg-gradient-neon rounded-full transition-all duration-500"
            style={{
              width: `${((quesNum + 1) / filteredQuizzes.length) * 100}%`,
            }}
          ></div>
        </div>
      </div>
      
      {/* Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ù…Ø¹ ØªØ£Ø«ÙŠØ±Ø§Øª Ø¨ØµØ±ÙŠØ© */}
      <div className="space-y-4">
        {quiz.options.map((option, idx) => {
          let optionStyle = "card-gradient border-cyber-700/50";
          let textColor = "text-white";

          if (selectedOption) {
            if (option === quiz.correct_answer) {
              optionStyle = "bg-neon-green/20 border-neon-green/50";
              textColor = "text-neon-green";
            } else if (option === selectedOption && option !== quiz.correct_answer) {
              optionStyle = "bg-neon-red/20 border-neon-red/50";
              textColor = "text-neon-red";
            }
          }

          return (
            <label
              key={idx}
              onClick={() => !selectedOption && handleAnswer(option)}
              className={`flex items-center ${optionStyle} rounded-xl px-6 py-4 cursor-pointer transition-all duration-300 hover-lift border backdrop-blur-md ${
                !selectedOption ? "hover:border-neon-blue/50" : ""
              }`}
            >
              <input
                type="radio"
                name="question"
                value={option}
                className="mr-4 accent-neon-blue"
                checked={selectedOption === option}
                readOnly
              />
              <span className={`text-lg ${textColor}`}>{option}</span>
            </label>
          );
        })}
      </div>
    </div>
  );
}
```

#### Ø¬) Ù†Ø¸Ø§Ù… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…

**1. Ù…ÙƒÙˆÙ† ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª:**
```jsx
// Ù…ÙƒÙˆÙ† VoicePopup Ù…Ø¹ WaveSurfer.js
import WaveSurfer from "wavesurfer.js";
import MicrophonePlugin from "wavesurfer.js/dist/plugin/wavesurfer.microphone.min.js";

export default function VoicePopup({ targetWord, targetLetter, onClose, onResult }) {
  const waveformRef = useRef(null);
  const wavesurfer = useRef(null);
  const [isListening, setIsListening] = useState(false);
  const [mediaRecorder, setMediaRecorder] = useState(null);
  const [audioChunks, setAudioChunks] = useState([]);
  const [isProcessing, setIsProcessing] = useState(false);

  // Ø¥Ø¹Ø¯Ø§Ø¯ WaveSurfer Ù„Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¨ØµØ±ÙŠ
  useEffect(() => {
    if (isListening && waveformRef.current) {
      wavesurfer.current = WaveSurfer.create({
        container: waveformRef.current,
        waveColor: "#0ff",
        interact: false,
        cursorWidth: 0,
        height: 100,
        plugins: [MicrophonePlugin.create()],
      });

      wavesurfer.current.microphone.on("deviceReady", () => {
        console.log("ğŸ™ï¸ Microphone ready");
      });

      wavesurfer.current.microphone.start();
    }

    return () => {
      if (wavesurfer.current) {
        wavesurfer.current.destroy();
        wavesurfer.current = null;
      }
    };
  }, [isListening]);

  // Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      const mimeType = MediaRecorder.isTypeSupported("audio/webm;codecs=opus")
        ? "audio/webm;codecs=opus"
        : "audio/ogg;codecs=opus";

      const recorder = new MediaRecorder(stream, { mimeType });
      setAudioChunks([]);

      recorder.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) {
          setAudioChunks((prev) => [...prev, e.data]);
        }
      };

      recorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: mimeType });
        const ext = mimeType.includes("webm") ? "webm" : "ogg";
        
        // Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª Ù„Ù„ØªØ­Ù„ÙŠÙ„
        const formData = new FormData();
        formData.append("audio", audioBlob, `recorded_audio.${ext}`);
        formData.append("target_word", targetWord);
        formData.append("target_char", targetLetter);

        try {
          setIsProcessing(true);
          const response = await fetch("http://localhost:9999/api/transcribe/", {
            method: "POST",
            body: formData,
          });
          const data = await response.json();
          setLocalResult(data);
        } catch (err) {
          console.error("âŒ ÙØ´Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª:", err);
        } finally {
          setIsProcessing(false);
        }
      };

      recorder.start();
      setIsListening(true);
      setMediaRecorder(recorder);
    } catch (err) {
      console.error("ÙØ´Ù„ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ù…Ø§ÙŠÙƒØ±ÙˆÙÙˆÙ†:", err);
    }
  };

  return (
    <div className="fixed inset-0 bg-black/20 backdrop-blur-md flex items-center justify-center z-50">
      <div className="bg-cyber-900 p-6 rounded-2xl shadow-xl border border-neon-green/40 min-w-[400px] max-w-lg relative overflow-hidden">
        {/* Ù…Ø¤Ø´Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ */}
        {isProcessing && !localResult && (
          <div className="text-center mt-4">
            <div className="flex items-center justify-center gap-3 mb-2">
              <div className="w-4 h-4 bg-cyan-500 rounded-full animate-pulse"></div>
              <div className="w-4 h-4 bg-purple-500 rounded-full animate-pulse" style={{ animationDelay: "0.2s" }}></div>
              <div className="w-4 h-4 bg-pink-500 rounded-full animate-pulse" style={{ animationDelay: "0.4s" }}></div>
            </div>
            <p className="text-neon-blue animate-pulse font-medium">
              ğŸ” Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ...
            </p>
          </div>
        )}
        
        {/* Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© */}
        {localResult && (
          <div className="text-center mt-4">
            <div className="bg-gradient-to-r from-cyber-800 to-cyber-700 p-4 rounded-xl border border-cyan-500/20 mb-4">
              <p className={`text-lg ${localResult.test_passed ? "text-green-400" : "text-red-300"}`}>
                {localResult.test_passed
                  ? "âœ… ØªÙ‡Ø§Ù†ÙŠÙ†Ø§! Ù„Ù‚Ø¯ Ù„ÙØ¸Øª Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­"
                  : `âŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ØŒ Ù„Ù… ØªÙ„ÙØ¸ Ø§Ù„Ø­Ø±Ù "${targetLetter}" Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.`}
              </p>
              <div className="flex items-center justify-center gap-2 mt-2">
                <span className="text-cyber-200 text-sm">Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚:</span>
                <span className="text-cyan-400 font-bold">{localResult.similarity_percentage}%</span>
                <span className="text-cyber-400 text-xs">(AI Analysis)</span>
              </div>
            </div>
          </div>
        )}
      </div>
    </div>
  );
}
```

#### Ø¯) Ù†Ø¸Ø§Ù… Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…ØªØ¬Ø§ÙˆØ¨ ÙˆØ§Ù„Ø­Ø±ÙƒØ§Øª

**1. Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…ØªØ¬Ø§ÙˆØ¨:**
```css
/* Ø§Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ù…ØªØ¬Ø§ÙˆØ¨ */
.grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
  gap: 2rem;
}

/* Ø§Ù„ØªØ®Ø·ÙŠØ· Ù„Ù„Ø´Ø§Ø´Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© */
@media (max-width: 768px) {
  .grid {
    grid-template-columns: 1fr;
    gap: 1rem;
  }
}

/* Ø§Ù„ØªØ®Ø·ÙŠØ· Ù„Ù„Ø´Ø§Ø´Ø§Øª Ø§Ù„Ù…ØªÙˆØ³Ø·Ø© */
@media (min-width: 769px) and (max-width: 1024px) {
  .grid {
    grid-template-columns: repeat(2, 1fr);
    gap: 1.5rem;
  }
}

/* Ø§Ù„ØªØ®Ø·ÙŠØ· Ù„Ù„Ø´Ø§Ø´Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© */
@media (min-width: 1025px) {
  .grid {
    grid-template-columns: repeat(3, 1fr);
    gap: 2rem;
  }
}
```

**2. Ø§Ù„Ø­Ø±ÙƒØ§Øª ÙˆØ§Ù„ØªØ£Ø«ÙŠØ±Ø§Øª:**
```css
/* ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø­Ø±ÙƒØ© */
@keyframes fade-in-up {
  from {
    opacity: 0;
    transform: translateY(30px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

@keyframes float {
  0%, 100% {
    transform: translateY(0px);
  }
  50% {
    transform: translateY(-20px);
  }
}

@keyframes pulse {
  0%, 100% {
    opacity: 1;
  }
  50% {
    opacity: 0.5;
  }
}

/* ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ø±ÙƒØ§Øª */
.animate-fade-in-up {
  animation: fade-in-up 0.6s ease-out;
}

.animate-float {
  animation: float 3s ease-in-out infinite;
}

.animate-pulse {
  animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
}
```

#### Ù‡Ù€) Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„Ø© ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

**1. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©:**
```jsx
// Ø¥Ø¯Ø§Ø±Ø© ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ localStorage
const saveProgress = (letter, level) => {
  const passed = JSON.parse(localStorage.getItem("passedLevels")) || [];
  const newPassed = { letter, level };
  
  const alreadyPassed = passed.some(
    (item) => item.letter === newPassed.letter && item.level === newPassed.level
  );
  
  if (!alreadyPassed) {
    passed.push(newPassed);
    localStorage.setItem("passedLevels", JSON.stringify(passed));
  }
};

const getProgress = () => {
  return JSON.parse(localStorage.getItem("passedLevels")) || [];
};

const isLevelCompleted = (letter, level) => {
  const passed = getProgress();
  return passed.some(
    (item) => item.letter === letter && item.level === level
  );
};
```

**2. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø®Ø§Ø¯Ù…:**
```jsx
// Hook Ù…Ø®ØµØµ Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
const useApiData = (url, dependencies = []) => {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);

  useEffect(() => {
    const fetchData = async () => {
      try {
        setLoading(true);
        const response = await fetch(url);
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        const result = await response.json();
        setData(result);
      } catch (err) {
        setError(err.message);
      } finally {
        setLoading(false);
      }
    };

    fetchData();
  }, dependencies);

  return { data, loading, error };
};

// Ø§Ø³ØªØ®Ø¯Ø§Ù… Hook
const { data: letters, loading, error } = useApiData(`http://localhost:9999/api/${lan}/letters/`, [lan]);
```

#### Ùˆ) Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„ØªØ­Ù‚Ù‚

**1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆÙƒÙ†:**
```jsx
// Hook Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©
const useAuth = () => {
  const [isAuthenticated, setIsAuthenticated] = useState(false);
  const [user, setUser] = useState(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const token = localStorage.getItem("token");
    if (token) {
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØªÙˆÙƒÙ†
      fetch("http://localhost:9999/api/profile/", {
        headers: {
          Authorization: `Token ${token}`,
        },
      })
        .then((res) => {
          if (res.ok) {
            return res.json();
          }
          throw new Error("Invalid token");
        })
        .then((data) => {
          setIsAuthenticated(true);
          setUser(data);
        })
        .catch(() => {
          localStorage.removeItem("token");
          setIsAuthenticated(false);
        })
        .finally(() => {
          setLoading(false);
        });
    } else {
      setLoading(false);
    }
  }, []);

  return { isAuthenticated, user, loading };
};
```

**2. Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª:**
```jsx
// Ù…ÙƒÙˆÙ† Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
const ProtectedRoute = ({ children }) => {
  const { isAuthenticated, loading } = useAuth();
  const navigate = useNavigate();

  useEffect(() => {
    if (!loading && !isAuthenticated) {
      navigate("/login");
    }
  }, [isAuthenticated, loading, navigate]);

  if (loading) {
    return <div className="spinner"></div>;
  }

  return isAuthenticated ? children : null;
};
```

### 6. Ù†Ø¸Ø§Ù… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù… (Text-to-Speech - TTS)

#### Ø£) ØªÙ‚Ù†ÙŠØ© XTTS Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
```python
"""
Ù†Ø¸Ø§Ù… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… XTTS v2
"""
import torch
from TTS.api import TTS
from TTS.config.shared_configs import BaseDatasetConfig
from TTS.tts.configs.xtts_config import XttsConfig
from TTS.tts.models.xtts import XttsArgs, XttsAudioConfig

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¢Ù…Ù†
torch.serialization.add_safe_globals([
    XttsConfig, 
    XttsAudioConfig, 
    BaseDatasetConfig, 
    XttsArgs
])

class ArabicTTS:
    def __init__(self):
        self.model_name = "tts_models/multilingual/multi-dataset/xtts_v2"
        self.tts = TTS(self.model_name)
        self.supported_languages = ["ar", "en", "fr", "es", "de"]
    
    def generate_speech(self, text, language="ar", speaker_wav="arabic_voice.wav", output_path=None):
        """
        ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù…Ù† Ø§Ù„Ù†Øµ
        """
        try:
            if not output_path:
                output_path = f"./pronunciation_api/media/{text}.wav"
            
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù…
            self.tts.tts_to_file(
                text=text,
                speaker_wav=speaker_wav,
                language=language,
                file_path=output_path,
            )
            
            return {
                "success": True,
                "file_path": output_path,
                "text": text,
                "language": language
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def batch_generate(self, texts, language="ar", speaker_wav="arabic_voice.wav"):
        """
        ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù„Ø¹Ø¯Ø© Ù†ØµÙˆØµ Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©
        """
        results = []
        for text in texts:
            result = self.generate_speech(text, language, speaker_wav)
            results.append(result)
        return results

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
tts_system = ArabicTTS()

# ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù„ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©
result = tts_system.generate_speech("Ù…Ø³Ù…Ø§Ø±", "ar", "arabic_voice.wav")

# ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù„Ø¹Ø¯Ø© ÙƒÙ„Ù…Ø§Øª
words = ["Ø£Ø±Ù†Ø¨", "ØªÙØ§Ø­Ø©", "Ù…Ø¯Ø±Ø³Ø©", "ÙƒØªØ§Ø¨", "Ù‚Ù„Ù…"]
batch_results = tts_system.batch_generate(words, "ar", "arabic_voice.wav")
```

#### Ø¨) ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª
```python
class AudioEnhancer:
    """Ù…Ø­Ø³Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª"""
    
    def __init__(self):
        self.sample_rate = 22050
        self.channels = 1
    
    def enhance_audio(self, input_path, output_path):
        """
        ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª
        """
        import librosa
        import soundfile as sf
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª
        audio, sr = librosa.load(input_path, sr=self.sample_rate)
        
        # ØªØ·Ø¨ÙŠÙ‚ ÙÙ„ØªØ± Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
        audio_enhanced = self.remove_noise(audio)
        
        # ØªØ·Ø¨ÙŠØ¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª
        audio_normalized = self.normalize_audio(audio_enhanced)
        
        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø­Ø³Ù†
        sf.write(output_path, audio_normalized, self.sample_rate)
        
        return output_path
    
    def remove_noise(self, audio):
        """
        Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ù…Ù† Ø§Ù„ØµÙˆØª
        """
        # ØªØ·Ø¨ÙŠÙ‚ ÙÙ„ØªØ± Ù…Ø±Ø´Ø­
        from scipy import signal
        
        # ØªØµÙ…ÙŠÙ… ÙÙ„ØªØ± Ù…Ø±Ø´Ø­
        nyquist = self.sample_rate / 2
        low = 80 / nyquist
        high = 8000 / nyquist
        
        b, a = signal.butter(4, [low, high], btype='band')
        filtered_audio = signal.filtfilt(b, a, audio)
        
        return filtered_audio
    
    def normalize_audio(self, audio):
        """
        ØªØ·Ø¨ÙŠØ¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª
        """
        # ØªØ·Ø¨ÙŠØ¹ RMS
        rms = np.sqrt(np.mean(audio**2))
        target_rms = 0.1
        normalized_audio = audio * (target_rms / rms)
        
        # Ù‚Øµ Ø§Ù„Ù‚Ù…Ù…
        normalized_audio = np.clip(normalized_audio, -0.95, 0.95)
        
        return normalized_audio

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø­Ø³Ù† Ø§Ù„ØµÙˆØª
enhancer = AudioEnhancer()
enhanced_path = enhancer.enhance_audio("input.wav", "enhanced.wav")
```

#### Ø¬) Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£ØµÙˆØ§Øª
```python
class VoiceManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„Ø£ØµÙˆØ§Øª ÙˆØ§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©"""
    
    def __init__(self):
        self.voices_dir = "./pronunciation_api/media/voices/"
        self.letters_dir = "./pronunciation_api/media/letters/"
        self.levels_dir = "./pronunciation_api/media/levels/"
        
    def create_voice_profile(self, name, sample_audio_path):
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØµÙˆØªÙŠ Ø´Ø®ØµÙŠ
        """
        import os
        import shutil
        
        profile_dir = os.path.join(self.voices_dir, name)
        os.makedirs(profile_dir, exist_ok=True)
        
        # Ù†Ø³Ø® Ø¹ÙŠÙ†Ø© Ø§Ù„ØµÙˆØª
        shutil.copy(sample_audio_path, os.path.join(profile_dir, "sample.wav"))
        
        return profile_dir
    
    def generate_letter_audio(self, letter, word, voice_profile):
        """
        ØªÙˆÙ„ÙŠØ¯ ØµÙˆØª Ù„Ù„Ø­Ø±Ù
        """
        tts = ArabicTTS()
        output_path = os.path.join(self.letters_dir, f"{word}.wav")
        
        result = tts.generate_speech(
            text=word,
            language="ar",
            speaker_wav=os.path.join(voice_profile, "sample.wav"),
            output_path=output_path
        )
        
        return result
    
    def generate_level_audio(self, level_word, voice_profile):
        """
        ØªÙˆÙ„ÙŠØ¯ ØµÙˆØª Ù„Ù„Ù…Ø³ØªÙˆÙ‰
        """
        tts = ArabicTTS()
        output_path = os.path.join(self.levels_dir, f"{level_word}.wav")
        
        result = tts.generate_speech(
            text=level_word,
            language="ar",
            speaker_wav=os.path.join(voice_profile, "sample.wav"),
            output_path=output_path
        )
        
        return result

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
voice_manager = VoiceManager()

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØµÙˆØªÙŠ Ø´Ø®ØµÙŠ
profile = voice_manager.create_voice_profile("teacher_ahmed", "sample_voice.wav")

# ØªÙˆÙ„ÙŠØ¯ Ø£ØµÙˆØ§Øª Ù„Ù„Ø­Ø±ÙˆÙ
letters = [
    ("Ø£", "Ø£Ø±Ù†Ø¨"),
    ("Ø¨", "Ø¨Ø·Ø©"),
    ("Øª", "ØªÙØ§Ø­Ø©"),
    ("Ø«", "Ø«Ø¹Ù„Ø¨")
]

for letter, word in letters:
    result = voice_manager.generate_letter_audio(letter, word, profile)
    print(f"ØªÙ… ØªÙˆÙ„ÙŠØ¯ ØµÙˆØª {word}: {result['success']}")
```

### 7. Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©

#### Ø£) Ù†Ø¸Ø§Ù… Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ (Futuristic Design)

**1. ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠØ©:**
```css
/* Ø®Ù„ÙÙŠØ© Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø³ÙŠØ¨Ø±Ø§Ù†ÙŠØ© */
.cyber-grid {
  background-image: 
    linear-gradient(rgba(0, 212, 255, 0.1) 1px, transparent 1px),
    linear-gradient(90deg, rgba(0, 212, 255, 0.1) 1px, transparent 1px);
  background-size: 50px 50px;
  animation: grid-move 20s linear infinite;
}

@keyframes grid-move {
  0% { transform: translate(0, 0); }
  100% { transform: translate(50px, 50px); }
}

/* ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ø¬Ø²ÙŠØ¦Ø§Øª */
.particles {
  position: relative;
  overflow: hidden;
}

.particles::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-image: 
    radial-gradient(circle at 20% 80%, rgba(0, 212, 255, 0.3) 0%, transparent 50%),
    radial-gradient(circle at 80% 20%, rgba(168, 85, 247, 0.3) 0%, transparent 50%),
    radial-gradient(circle at 40% 40%, rgba(0, 255, 136, 0.3) 0%, transparent 50%);
  animation: particles-float 10s ease-in-out infinite;
}

@keyframes particles-float {
  0%, 100% { transform: translateY(0px) rotate(0deg); }
  50% { transform: translateY(-20px) rotate(180deg); }
}
```

**2. ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªØ¯Ø±Ø¬:**
```css
/* Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªØ¯Ø±Ø¬ Ù…Ø¹ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø¸Ù„ */
.gradient-text {
  background: var(--gradient-neon);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  background-clip: text;
  position: relative;
}

.gradient-text::after {
  content: attr(data-text);
  position: absolute;
  left: 0;
  top: 0;
  z-index: -1;
  background: var(--gradient-neon);
  -webkit-background-clip: text;
  -webkit-text-fill-color: transparent;
  background-clip: text;
  filter: blur(8px);
  opacity: 0.7;
  pointer-events: none;
}
```

#### Ø¨) Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…

**1. Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©:**
```jsx
// Ù…ÙƒÙˆÙ† Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ
const ProgressBar = ({ current, total, label }) => {
  const percentage = (current / total) * 100;
  
  return (
    <div className="mb-8">
      <div className="flex justify-between items-center mb-2">
        <span className="text-cyber-300 text-sm">{label}</span>
        <span className="text-neon-blue font-semibold">
          {current}/{total}
        </span>
      </div>
      <div className="w-full bg-cyber-800 rounded-full h-2 overflow-hidden">
        <div
          className="h-full bg-gradient-neon rounded-full transition-all duration-500 relative"
          style={{ width: `${percentage}%` }}
        >
          {/* ØªØ£Ø«ÙŠØ± Ø§Ù„ØªÙˆÙ‡Ø¬ */}
          <div className="absolute inset-0 bg-gradient-to-r from-transparent via-white to-transparent opacity-30 animate-shimmer"></div>
        </div>
      </div>
    </div>
  );
};

// Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙƒÙˆÙ†
<ProgressBar 
  current={quesNum + 1} 
  total={filteredQuizzes.length} 
  label="Progress" 
/>
```

**2. Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…:**
```jsx
// Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ
const NotificationSystem = () => {
  const [notifications, setNotifications] = useState([]);
  
  const addNotification = (type, message, duration = 5000) => {
    const id = Date.now();
    const notification = {
      id,
      type, // 'success', 'error', 'warning', 'info'
      message,
      timestamp: new Date()
    };
    
    setNotifications(prev => [...prev, notification]);
    
    // Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¥Ø´Ø¹Ø§Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    setTimeout(() => {
      removeNotification(id);
    }, duration);
  };
  
  const removeNotification = (id) => {
    setNotifications(prev => prev.filter(n => n.id !== id));
  };
  
  return (
    <div className="fixed top-4 right-4 z-50 space-y-2">
      {notifications.map(notification => (
        <div
          key={notification.id}
          className={`notification-${notification.type} p-4 rounded-lg shadow-lg backdrop-blur-md border animate-slide-in-right`}
        >
          <div className="flex items-center justify-between">
            <span className="text-white">{notification.message}</span>
            <button
              onClick={() => removeNotification(notification.id)}
              className="text-white hover:text-neon-blue transition-colors"
            >
              Ã—
            </button>
          </div>
        </div>
      ))}
    </div>
  );
};

// Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ø¸Ø§Ù… Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª
const { addNotification } = useNotification();

// Ø¹Ù†Ø¯ Ø§Ù„Ù†Ø¬Ø§Ø­ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
addNotification('success', 'ğŸ‰ ØªÙ… Ø§Ø¬ØªÙŠØ§Ø² Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø¨Ù†Ø¬Ø§Ø­!');

// Ø¹Ù†Ø¯ Ø§Ù„Ø®Ø·Ø£
addNotification('error', 'âŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ØŒ Ù„Ù… ØªÙ„ÙØ¸ Ø§Ù„Ø­Ø±Ù Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­');
```

#### Ø¬) Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù„Ø¹Ø§Ø¨ ÙˆØ§Ù„ØªØ­ÙÙŠØ²

**1. Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆØ§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª:**
```jsx
// Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆØ§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª
const AchievementSystem = () => {
  const [points, setPoints] = useState(0);
  const [achievements, setAchievements] = useState([]);
  const [level, setLevel] = useState(1);
  
  const addPoints = (amount, reason) => {
    setPoints(prev => {
      const newPoints = prev + amount;
      
      // ÙØ­Øµ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
      checkAchievements(newPoints);
      
      // ÙØ­Øµ Ø§Ù„ØªØ±Ù‚ÙŠØ©
      checkLevelUp(newPoints);
      
      return newPoints;
    });
    
    // Ø¥Ø¸Ù‡Ø§Ø± Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ù†Ù‚Ø§Ø·
    showPointsNotification(amount, reason);
  };
  
  const checkAchievements = (totalPoints) => {
    const newAchievements = [];
    
    if (totalPoints >= 100 && !achievements.includes('first_100')) {
      newAchievements.push({
        id: 'first_100',
        title: 'Ø£ÙˆÙ„ 100 Ù†Ù‚Ø·Ø©',
        description: 'Ø­ØµÙ„Øª Ø¹Ù„Ù‰ Ø£ÙˆÙ„ 100 Ù†Ù‚Ø·Ø©!',
        icon: 'ğŸ†'
      });
    }
    
    if (totalPoints >= 500 && !achievements.includes('point_collector')) {
      newAchievements.push({
        id: 'point_collector',
        title: 'Ø¬Ø§Ù…Ø¹ Ø§Ù„Ù†Ù‚Ø§Ø·',
        description: 'Ø­ØµÙ„Øª Ø¹Ù„Ù‰ 500 Ù†Ù‚Ø·Ø©!',
        icon: 'â­'
      });
    }
    
    if (newAchievements.length > 0) {
      setAchievements(prev => [...prev, ...newAchievements]);
      newAchievements.forEach(achievement => {
        addNotification('success', `${achievement.icon} ${achievement.title}: ${achievement.description}`);
      });
    }
  };
  
  const checkLevelUp = (totalPoints) => {
    const newLevel = Math.floor(totalPoints / 100) + 1;
    if (newLevel > level) {
      setLevel(newLevel);
      addNotification('success', `ğŸ‰ ØªÙ… Ø§Ù„ØªØ±Ù‚ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ ${newLevel}!`);
    }
  };
  
  return (
    <div className="achievement-panel">
      <div className="points-display">
        <span className="text-neon-blue font-bold">{points} Ù†Ù‚Ø·Ø©</span>
        <span className="text-cyber-300">Ø§Ù„Ù…Ø³ØªÙˆÙ‰ {level}</span>
      </div>
      
      <div className="achievements-list">
        {achievements.map(achievement => (
          <div key={achievement.id} className="achievement-item">
            <span className="achievement-icon">{achievement.icon}</span>
            <div>
              <h4 className="achievement-title">{achievement.title}</h4>
              <p className="achievement-description">{achievement.description}</p>
            </div>
          </div>
        ))}
      </div>
    </div>
  );
};

// Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‚Ø§Ø·
const { addPoints } = useAchievementSystem();

// Ø¹Ù†Ø¯ Ø§Ø¬ØªÙŠØ§Ø² Ù…Ø³ØªÙˆÙ‰
addPoints(10, 'Ø§Ø¬ØªÙŠØ§Ø² Ù…Ø³ØªÙˆÙ‰');

// Ø¹Ù†Ø¯ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¯Ø±Ø¬Ø© Ù…Ø«Ø§Ù„ÙŠØ©
addPoints(25, 'Ø¯Ø±Ø¬Ø© Ù…Ø«Ø§Ù„ÙŠØ©');
```

**2. Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ø¯ÙŠØ§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ©:**
```jsx
// Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ø¯ÙŠØ§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ©
const DailyChallenges = () => {
  const [challenges, setChallenges] = useState([]);
  const [completedToday, setCompletedToday] = useState([]);
  
  useEffect(() => {
    // ØªÙˆÙ„ÙŠØ¯ ØªØ­Ø¯ÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø© ÙƒÙ„ ÙŠÙˆÙ…
    generateDailyChallenges();
  }, []);
  
  const generateDailyChallenges = () => {
    const dailyChallenges = [
      {
        id: 'practice_5_letters',
        title: 'ØªØ¯Ø±Ø¨ Ø¹Ù„Ù‰ 5 Ø£Ø­Ø±Ù',
        description: 'Ø£ÙƒÙ…Ù„ 5 Ø£Ø­Ø±Ù Ø§Ù„ÙŠÙˆÙ…',
        target: 5,
        reward: 50,
        type: 'letters_completed'
      },
      {
        id: 'perfect_score',
        title: 'Ø¯Ø±Ø¬Ø© Ù…Ø«Ø§Ù„ÙŠØ©',
        description: 'Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø¯Ø±Ø¬Ø© Ù…Ø«Ø§Ù„ÙŠØ© ÙÙŠ Ø£ÙŠ Ù…Ø³ØªÙˆÙ‰',
        target: 1,
        reward: 100,
        type: 'perfect_scores'
      },
      {
        id: 'practice_10_minutes',
        title: 'ØªØ¯Ø±Ø¨ Ù„Ù…Ø¯Ø© 10 Ø¯Ù‚Ø§Ø¦Ù‚',
        description: 'Ø§Ù‚Ø¶Ù 10 Ø¯Ù‚Ø§Ø¦Ù‚ ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨',
        target: 600, // Ø«Ø§Ù†ÙŠØ©
        reward: 75,
        type: 'practice_time'
      }
    ];
    
    setChallenges(dailyChallenges);
  };
  
  const checkChallengeProgress = (type, amount = 1) => {
    challenges.forEach(challenge => {
      if (challenge.type === type && !completedToday.includes(challenge.id)) {
        // ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
        const progress = getChallengeProgress(challenge.id);
        const newProgress = progress + amount;
        
        if (newProgress >= challenge.target) {
          // Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªØ­Ø¯ÙŠ
          completeChallenge(challenge);
        } else {
          // ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…
          updateChallengeProgress(challenge.id, newProgress);
        }
      }
    });
  };
  
  const completeChallenge = (challenge) => {
    setCompletedToday(prev => [...prev, challenge.id]);
    addPoints(challenge.reward, `ØªØ­Ø¯ÙŠ: ${challenge.title}`);
    addNotification('success', `ğŸ¯ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ØªØ­Ø¯ÙŠ: ${challenge.title}!`);
  };
  
  return (
    <div className="daily-challenges">
      <h3 className="text-xl font-bold text-white mb-4">Ø§Ù„ØªØ­Ø¯ÙŠØ§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ©</h3>
      
      <div className="space-y-4">
        {challenges.map(challenge => {
          const isCompleted = completedToday.includes(challenge.id);
          const progress = getChallengeProgress(challenge.id);
          const percentage = Math.min((progress / challenge.target) * 100, 100);
          
          return (
            <div
              key={challenge.id}
              className={`challenge-card ${isCompleted ? 'completed' : ''}`}
            >
              <div className="flex items-center justify-between mb-2">
                <h4 className="challenge-title">{challenge.title}</h4>
                <span className="challenge-reward">+{challenge.reward} Ù†Ù‚Ø·Ø©</span>
              </div>
              
              <p className="challenge-description">{challenge.description}</p>
              
              <div className="challenge-progress mt-3">
                <div className="progress-bar">
                  <div
                    className="progress-fill"
                    style={{ width: `${percentage}%` }}
                  ></div>
                </div>
                <span className="progress-text">
                  {progress}/{challenge.target}
                </span>
              </div>
              
              {isCompleted && (
                <div className="completion-badge">
                  <span>âœ… Ù…ÙƒØªÙ…Ù„</span>
                </div>
              )}
            </div>
          );
        })}
      </div>
    </div>
  );
};
```

#### Ø¯) Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª ÙˆØ§Ù„ØªÙ‚Ø§Ø±ÙŠØ±

**1. Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø´Ø®ØµÙŠØ©:**
```jsx
// Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø´Ø®ØµÙŠØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
const PersonalDashboard = () => {
  const [stats, setStats] = useState({
    totalLettersCompleted: 0,
    totalLevelsCompleted: 0,
    totalPracticeTime: 0,
    averageScore: 0,
    currentStreak: 0,
    bestStreak: 0
  });
  
  const [recentActivity, setRecentActivity] = useState([]);
  const [learningPath, setLearningPath] = useState([]);
  
  useEffect(() => {
    loadUserStats();
    loadRecentActivity();
    generateLearningPath();
  }, []);
  
  const loadUserStats = async () => {
    try {
      const response = await fetch('/api/user/stats');
      const data = await response.json();
      setStats(data);
    } catch (error) {
      console.error('ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª:', error);
    }
  };
  
  const loadRecentActivity = async () => {
    try {
      const response = await fetch('/api/user/recent-activity');
      const data = await response.json();
      setRecentActivity(data);
    } catch (error) {
      console.error('ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø£Ø®ÙŠØ±:', error);
    }
  };
  
  const generateLearningPath = () => {
    // ØªÙˆÙ„ÙŠØ¯ Ù…Ø³Ø§Ø± Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡
    const path = [
      { type: 'letter', id: 'Ø£', status: 'completed' },
      { type: 'letter', id: 'Ø¨', status: 'in_progress' },
      { type: 'letter', id: 'Øª', status: 'locked' },
      { type: 'skill', id: 'pronunciation', status: 'locked' }
    ];
    setLearningPath(path);
  };
  
  return (
    <div className="personal-dashboard">
      {/* Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø© */}
      <div className="stats-grid">
        <div className="stat-card">
          <div className="stat-icon">ğŸ“š</div>
          <div className="stat-content">
            <h4 className="stat-title">Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©</h4>
            <p className="stat-value">{stats.totalLettersCompleted}</p>
          </div>
        </div>
        
        <div className="stat-card">
          <div className="stat-icon">ğŸ¯</div>
          <div className="stat-content">
            <h4 className="stat-title">Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©</h4>
            <p className="stat-value">{stats.totalLevelsCompleted}</p>
          </div>
        </div>
        
        <div className="stat-card">
          <div className="stat-icon">â±ï¸</div>
          <div className="stat-content">
            <h4 className="stat-title">ÙˆÙ‚Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨</h4>
            <p className="stat-value">{formatTime(stats.totalPracticeTime)}</p>
          </div>
        </div>
        
        <div className="stat-card">
          <div className="stat-icon">ğŸ”¥</div>
          <div className="stat-content">
            <h4 className="stat-title">Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ</h4>
            <p className="stat-value">{stats.currentStreak} Ø£ÙŠØ§Ù…</p>
          </div>
        </div>
      </div>
      
      {/* Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø£Ø®ÙŠØ± */}
      <div className="recent-activity">
        <h3 className="section-title">Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ø£Ø®ÙŠØ±</h3>
        <div className="activity-list">
          {recentActivity.map(activity => (
            <div key={activity.id} className="activity-item">
              <div className="activity-icon">{activity.icon}</div>
              <div className="activity-content">
                <p className="activity-description">{activity.description}</p>
                <span className="activity-time">{formatTimeAgo(activity.timestamp)}</span>
              </div>
            </div>
          ))}
        </div>
      </div>
      
      {/* Ù…Ø³Ø§Ø± Ø§Ù„ØªØ¹Ù„Ù… */}
      <div className="learning-path">
        <h3 className="section-title">Ù…Ø³Ø§Ø± Ø§Ù„ØªØ¹Ù„Ù…</h3>
        <div className="path-visualization">
          {learningPath.map((item, index) => (
            <div key={item.id} className={`path-item ${item.status}`}>
              <div className="path-icon">{item.icon}</div>
              <div className="path-content">
                <h4 className="path-title">{item.title}</h4>
                <p className="path-description">{item.description}</p>
              </div>
              {index < learningPath.length - 1 && (
                <div className="path-connector"></div>
              )}
            </div>
          ))}
        </div>
      </div>
    </div>
  );
};

// Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
const formatTime = (seconds) => {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  
  if (hours > 0) {
    return `${hours}Ø³ ${minutes}Ø¯`;
  }
  return `${minutes} Ø¯Ù‚ÙŠÙ‚Ø©`;
};

const formatTimeAgo = (timestamp) => {
  const now = new Date();
  const time = new Date(timestamp);
  const diffInMinutes = Math.floor((now - time) / (1000 * 60));
  
  if (diffInMinutes < 1) return 'Ø§Ù„Ø¢Ù†';
  if (diffInMinutes < 60) return `Ù…Ù†Ø° ${diffInMinutes} Ø¯Ù‚ÙŠÙ‚Ø©`;
  if (diffInMinutes < 1440) return `Ù…Ù†Ø° ${Math.floor(diffInMinutes / 60)} Ø³Ø§Ø¹Ø©`;
  return `Ù…Ù†Ø° ${Math.floor(diffInMinutes / 1440)} ÙŠÙˆÙ…`;
};
```

Ù‡Ø°Ù‡ Ø§Ù„Ø¥Ø¶Ø§ÙØ§Øª ØªØ¬Ø¹Ù„ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø£ÙƒØ«Ø± ØªÙØ§Ø¹Ù„ÙŠØ© ÙˆØ¬Ø§Ø°Ø¨ÙŠØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†ØŒ Ù…Ø¹ ØªÙˆÙÙŠØ± ØªØ¬Ø±Ø¨Ø© ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆÙ…Ø­ÙØ²Ø©.

### 8. ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ TTS Ù…Ø®ØµØµ (Custom TTS Model Training)

#### Ø£) Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨

**1. Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:**
```python
"""
Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ TTS Ù…Ø®ØµØµ
"""
import os
import shutil
from pathlib import Path

class TTSDataPreparation:
    def __init__(self, base_dir="./custom_tts_data"):
        self.base_dir = Path(base_dir)
        self.setup_directory_structure()
    
    def setup_directory_structure(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        directories = [
            "raw_audio",           # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            "processed_audio",      # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            "transcripts",          # Ù†ØµÙˆØµ Ø§Ù„Ù†Ø·Ù‚
            "metadata",            # Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©
            "validation",          # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚
            "test",                # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
            "models",              # Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©
            "logs",                # Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            "checkpoints"          # Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ­Ù‚Ù‚
        ]
        
        for dir_name in directories:
            dir_path = self.base_dir / dir_name
            dir_path.mkdir(parents=True, exist_ok=True)
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯: {dir_path}")
    
    def organize_audio_files(self, source_dir, target_format="wav"):
        """
        ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
        """
        source_path = Path(source_dir)
        target_dir = self.base_dir / "raw_audio"
        
        # Ø¯Ø¹Ù… Ø§Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
        supported_formats = ['.mp3', '.wav', '.flac', '.m4a', '.ogg']
        
        for audio_file in source_path.rglob("*"):
            if audio_file.suffix.lower() in supported_formats:
                # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ WAV Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
                if audio_file.suffix.lower() != '.wav':
                    converted_file = self.convert_to_wav(audio_file, target_dir)
                else:
                    converted_file = target_dir / audio_file.name
                    shutil.copy2(audio_file, converted_file)
                
                print(f"âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø©: {audio_file.name}")
        
        return target_dir
    
    def convert_to_wav(self, input_file, output_dir, sample_rate=22050):
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ WAV
        """
        import librosa
        import soundfile as sf
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª
        audio, sr = librosa.load(input_file, sr=sample_rate)
        
        # Ø­ÙØ¸ ÙƒÙ€ WAV
        output_file = output_dir / f"{input_file.stem}.wav"
        sf.write(output_file, audio, sample_rate)
        
        return output_file

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
data_prep = TTSDataPreparation("./my_custom_tts")
data_prep.organize_audio_files("./my_voice_samples")
```

**2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ù†Ø·Ù‚:**
```python
class TranscriptPreparation:
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.transcripts_dir = self.data_dir / "transcripts"
        self.metadata_dir = self.data_dir / "metadata"
    
    def create_transcript_file(self, audio_file, text, language="ar"):
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ù†ØµÙŠ Ù„Ù„Ù†Ø·Ù‚
        """
        transcript_file = self.transcripts_dir / f"{audio_file.stem}.txt"
        
        with open(transcript_file, 'w', encoding='utf-8') as f:
            f.write(text.strip())
        
        return transcript_file
    
    def create_metadata_file(self, audio_files, transcripts):
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
        """
        metadata_file = self.metadata_dir / "metadata.csv"
        
        with open(metadata_file, 'w', encoding='utf-8') as f:
            f.write("audio_file,text,language\n")
            
            for audio_file, text in zip(audio_files, transcripts):
                relative_path = audio_file.relative_to(self.data_dir / "processed_audio")
                f.write(f"{relative_path},{text},{language}\n")
        
        return metadata_file

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
transcript_prep = TranscriptPreparation("./my_custom_tts")

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ØµÙˆØµ
audio_files = list(Path("./my_custom_tts/processed_audio").glob("*.wav"))
transcripts = [
    "Ù…Ø±Ø­Ø¨Ø§ ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ",
    "Ø£Ù†Ø§ Ø£ØªØ¹Ù„Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
    "Ù‡Ø°Ø§ ØªØ·Ø¨ÙŠÙ‚ Ø±Ø§Ø¦Ø¹",
    "Ø´ÙƒØ±Ø§ Ù„Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©"
]

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†ØµÙˆØµ
for audio_file, text in zip(audio_files, transcripts):
    transcript_prep.create_transcript_file(audio_file, text)

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©
metadata_file = transcript_prep.create_metadata_file(audio_files, transcripts)
```

#### Ø¨) Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ©

**1. ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª:**
```python
class AudioPreprocessor:
    def __init__(self, sample_rate=22050, target_duration=10):
        self.sample_rate = sample_rate
        self.target_duration = target_duration
    
    def preprocess_audio(self, input_file, output_file):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
        """
        import librosa
        import soundfile as sf
        import numpy as np
        from scipy import signal
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª
        audio, sr = librosa.load(input_file, sr=self.sample_rate)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
        audio_denoised = self.remove_noise(audio)
        
        # ØªØ·Ø¨ÙŠØ¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª
        audio_normalized = self.normalize_audio(audio_denoised)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª
        audio_trimmed = self.trim_silence(audio_normalized)
        
        # Ø¶Ø¨Ø· Ø§Ù„Ù…Ø¯Ø©
        audio_padded = self.pad_or_trim(audio_trimmed)
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬
        sf.write(output_file, audio_padded, self.sample_rate)
        
        return output_file
    
    def remove_noise(self, audio, noise_reduce_level=0.1):
        """
        Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙ„ØªØ± Ù…Ø±Ø´Ø­
        """
        from scipy import signal
        
        # ØªØµÙ…ÙŠÙ… ÙÙ„ØªØ± Ù…Ø±Ø´Ø­
        nyquist = self.sample_rate / 2
        low = 80 / nyquist
        high = 8000 / nyquist
        
        b, a = signal.butter(4, [low, high], btype='band')
        filtered_audio = signal.filtfilt(b, a, audio)
        
        return filtered_audio
    
    def normalize_audio(self, audio, target_rms=0.1):
        """
        ØªØ·Ø¨ÙŠØ¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª
        """
        rms = np.sqrt(np.mean(audio**2))
        if rms > 0:
            normalized_audio = audio * (target_rms / rms)
            # Ù‚Øµ Ø§Ù„Ù‚Ù…Ù…
            normalized_audio = np.clip(normalized_audio, -0.95, 0.95)
            return normalized_audio
        return audio
    
    def trim_silence(self, audio, threshold=0.01):
        """
        Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª Ù…Ù† Ø¨Ø¯Ø§ÙŠØ© ÙˆÙ†Ù‡Ø§ÙŠØ© Ø§Ù„Ù…Ù„Ù
        """
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
        start_idx = np.where(np.abs(audio) > threshold)[0]
        if len(start_idx) > 0:
            audio = audio[start_idx[0]:]
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª Ù…Ù† Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
        end_idx = np.where(np.abs(audio) > threshold)[0]
        if len(end_idx) > 0:
            audio = audio[:end_idx[-1] + 1]
        
        return audio
    
    def pad_or_trim(self, audio):
        """
        Ø¶Ø¨Ø· Ù…Ø¯Ø© Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        """
        target_length = self.sample_rate * self.target_duration
        
        if len(audio) > target_length:
            # ØªÙ‚ØµÙŠØ± Ø§Ù„ØµÙˆØª
            audio = audio[:target_length]
        elif len(audio) < target_length:
            # Ø¥Ø·Ø§Ù„Ø© Ø§Ù„ØµÙˆØª Ø¨Ø§Ù„ØµÙ…Øª
            padding_length = target_length - len(audio)
            padding = np.zeros(padding_length)
            audio = np.concatenate([audio, padding])
        
        return audio

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
preprocessor = AudioPreprocessor(sample_rate=22050, target_duration=10)

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©
raw_audio_dir = Path("./my_custom_tts/raw_audio")
processed_audio_dir = Path("./my_custom_tts/processed_audio")

for audio_file in raw_audio_dir.glob("*.wav"):
    output_file = processed_audio_dir / audio_file.name
    preprocessor.preprocess_audio(audio_file, output_file)
    print(f"âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø©: {audio_file.name}")
```

#### Ø¬) Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨

**1. ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**
```python
class TTSModelConfig:
    def __init__(self, model_type="tacotron2"):
        self.model_type = model_type
        self.config = self.get_default_config()
    
    def get_default_config(self):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
        """
        if self.model_type == "tacotron2":
            return {
                "model": {
                    "encoder": {
                        "encoder_embedding_dim": 512,
                        "encoder_n_convolutions": 3,
                        "encoder_kernel_size": 5
                    },
                    "decoder": {
                        "decoder_rnn_dim": 1024,
                        "decoder_layer_norm": True,
                        "decoder_dropout": 0.1
                    },
                    "postnet": {
                        "postnet_embedding_dim": 512,
                        "postnet_kernel_size": 5,
                        "postnet_n_convolutions": 5
                    }
                },
                "training": {
                    "batch_size": 32,
                    "learning_rate": 0.001,
                    "epochs": 1000,
                    "gradient_clip_thresh": 1.0,
                    "weight_decay": 1e-6
                },
                "audio": {
                    "sample_rate": 22050,
                    "hop_length": 256,
                    "win_length": 1024,
                    "n_mel_channels": 80,
                    "mel_fmin": 0.0,
                    "mel_fmax": 8000.0
                }
            }
        elif self.model_type == "fastspeech2":
            return {
                "model": {
                    "encoder": {
                        "encoder_dim": 256,
                        "encoder_n_layer": 4,
                        "encoder_head": 2
                    },
                    "decoder": {
                        "decoder_dim": 256,
                        "decoder_n_layer": 4,
                        "decoder_head": 2
                    }
                },
                "training": {
                    "batch_size": 16,
                    "learning_rate": 0.0001,
                    "epochs": 1000
                }
            }
        
        return {}
    
    def save_config(self, config_path):
        """
        Ø­ÙØ¸ ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        """
        import json
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙƒÙˆÙŠÙ† ÙÙŠ: {config_path}")

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
config = TTSModelConfig("tacotron2")
config.save_config("./my_custom_tts/models/config.json")
```

#### Ø¯) ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†

**1. ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**
```python
class TTSEvaluator:
    def __init__(self, model_path, config_path):
        self.model_path = Path(model_path)
        self.config = self.load_config(config_path)
        self.model = self.load_model()
    
    def evaluate_model(self, test_file):
        """
        ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        """
        import pandas as pd
        import numpy as np
        
        df = pd.read_csv(test_file)
        results = []
        
        for _, row in df.iterrows():
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù…
            generated_audio = self.generate_speech(row['text'])
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ
            reference_audio = self.load_audio(row['audio_file'])
            
            # Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø¬ÙˆØ¯Ø©
            metrics = self.calculate_quality_metrics(generated_audio, reference_audio)
            results.append(metrics)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª
        avg_metrics = self.calculate_average_metrics(results)
        
        return avg_metrics
    
    def calculate_quality_metrics(self, generated_audio, reference_audio):
        """
        Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª
        """
        import librosa
        from scipy.stats import pearsonr
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…ÙŠØ²Ø§Øª Mel-spectrogram
        gen_mel = librosa.feature.melspectrogram(
            y=generated_audio, 
            sr=self.config['audio']['sample_rate']
        )
        ref_mel = librosa.feature.melspectrogram(
            y=reference_audio, 
            sr=self.config['audio']['sample_rate']
        )
        
        # Ø­Ø³Ø§Ø¨ MSE
        mse = np.mean((gen_mel - ref_mel) ** 2)
        
        # Ø­Ø³Ø§Ø¨ MAE
        mae = np.mean(np.abs(gen_mel - ref_mel))
        
        # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·
        correlation = pearsonr(gen_mel.flatten(), ref_mel.flatten())[0]
        
        return {
            'mse': mse,
            'mae': mae,
            'correlation': correlation
        }
    
    def calculate_average_metrics(self, results):
        """
        Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        """
        avg_metrics = {}
        for key in results[0].keys():
            values = [r[key] for r in results]
            avg_metrics[key] = np.mean(values)
            avg_metrics[f"{key}_std"] = np.std(values)
        
        return avg_metrics

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
evaluator = TTSEvaluator(
    model_path="./my_custom_tts/models/best_model.pth",
    config_path="./my_custom_tts/models/config.json"
)

metrics = evaluator.evaluate_model("./my_custom_tts/metadata/test.csv")
print("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:")
for metric, value in metrics.items():
    print(f"   {metric}: {value:.4f}")
```

#### Ù‡Ù€) Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨

**1. ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**
```python
class CustomTTSInference:
    def __init__(self, model_path, config_path, vocab_path):
        self.model_path = Path(model_path)
        self.config = self.load_config(config_path)
        self.vocab = self.load_vocabulary(vocab_path)
        self.model = self.load_model()
    
    def load_vocabulary(self, vocab_path):
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
        """
        with open(vocab_path, 'r', encoding='utf-8') as f:
            vocab = [line.strip() for line in f.readlines()]
        return vocab
    
    def text_to_sequence(self, text):
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ Ø£Ø±Ù‚Ø§Ù…
        """
        char_to_id = {char: i for i, char in enumerate(self.vocab)}
        sequence = [char_to_id.get(char, char_to_id['<unk>']) for char in text]
        sequence = [char_to_id['<sos>'] + sequence + [char_to_id['<eos>']]
        return sequence
    
    def generate_speech(self, text, output_path=None):
        """
        ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù…Ù† Ø§Ù„Ù†Øµ
        """
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„
        sequence = self.text_to_sequence(text)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù…
        with torch.no_grad():
            audio = self.model.inference(sequence)
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
        if output_path:
            import soundfile as sf
            sf.write(output_path, audio, self.config['audio']['sample_rate'])
        
        return audio
    
    def batch_generate(self, texts, output_dir):
        """
        ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù„Ø¹Ø¯Ø© Ù†ØµÙˆØµ Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©
        """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        results = []
        for i, text in enumerate(texts):
            output_path = output_dir / f"generated_{i:03d}.wav"
            audio = self.generate_speech(text, output_path)
            results.append({
                'text': text,
                'audio': audio,
                'file_path': output_path
            })
        
        return results

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
custom_tts = CustomTTSInference(
    model_path="./my_custom_tts/models/best_model.pth",
    config_path="./my_custom_tts/models/config.json",
    vocab_path="./my_custom_tts/models/vocab.txt"
)

# ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù„ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©
audio = custom_tts.generate_speech("Ù…Ø±Ø­Ø¨Ø§ ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ", "output.wav")

# ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù„Ø¹Ø¯Ø© ÙƒÙ„Ù…Ø§Øª
texts = [
    "Ø£Ù†Ø§ Ø£ØªØ¹Ù„Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
    "Ù‡Ø°Ø§ ØªØ·Ø¨ÙŠÙ‚ Ø±Ø§Ø¦Ø¹",
    "Ø´ÙƒØ±Ø§ Ù„Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©"
]

results = custom_tts.batch_generate(texts, "./generated_audio")
```

**2. ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®ØµØµ:**
```python
from flask import Flask, request, jsonify, send_file
import io

app = Flask(__name__)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®ØµØµ
custom_tts = CustomTTSInference(
    model_path="./my_custom_tts/models/best_model.pth",
    config_path="./my_custom_tts/models/config.json",
    vocab_path="./my_custom_tts/models/vocab.txt"
)

@app.route('/api/custom-tts/generate', methods=['POST'])
def generate_custom_speech():
    """
    ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®ØµØµ
    """
    try:
        data = request.get_json()
        text = data.get('text', '')
        language = data.get('language', 'ar')
        
        if not text:
            return jsonify({'error': 'Ø§Ù„Ù†Øµ Ù…Ø·Ù„ÙˆØ¨'}), 400
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù…
        audio = custom_tts.generate_speech(text)
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…Ù„Ù ØµÙˆØªÙŠ
        import soundfile as sf
        buffer = io.BytesIO()
        sf.write(buffer, audio, custom_tts.config['audio']['sample_rate'], format='WAV')
        buffer.seek(0)
        
        return send_file(
            buffer,
            mimetype='audio/wav',
            as_attachment=True,
            download_name=f'custom_tts_{text[:10]}.wav'
        )
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/custom-tts/batch-generate', methods=['POST'])
def batch_generate_custom_speech():
    """
    ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù„Ø¹Ø¯Ø© Ù†ØµÙˆØµ Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©
    """
    try:
        data = request.get_json()
        texts = data.get('texts', [])
        language = data.get('language', 'ar')
        
        if not texts:
            return jsonify({'error': 'Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ Ù…Ø·Ù„ÙˆØ¨Ø©'}), 400
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù…
        results = custom_tts.batch_generate(texts, "./temp_audio")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ZIP
        import zipfile
        import os
        
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
            for result in results:
                zip_file.write(result['file_path'], result['file_path'].name)
        
        zip_buffer.seek(0)
        
        return send_file(
            zip_buffer,
            mimetype='application/zip',
            as_attachment=True,
            download_name='custom_tts_batch.zip'
        )
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True, port=5001)
```

Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… ÙŠÙˆÙØ± Ø¯Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ TTS Ù…Ø®ØµØµ Ù…Ù† Ø§Ù„ØµÙØ±ØŒ Ø¨Ø¯Ø¡Ø§Ù‹ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù†ØªÙ‡Ø§Ø¡Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.

## Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª ÙˆØ§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©

### 1. Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª

#### Ø£) ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª
```python
# ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… FFmpeg
def convert_audio(input_file, output_file):
    subprocess.run([
        "ffmpeg", "-y", "-i", input_file,
        "-ar", "16000",  # Sample rate
        "-ac", "1",      # Mono
        "-c:a", "pcm_s16le",  # 16-bit PCM
        output_file
    ])
```

#### Ø¨) ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø·Ù‚
```python
# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø·Ù‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper
def transcribe_audio(audio_file):
    model = whisper.load_model("tiny")
    result = model.transcribe(audio_file, language="ar")
    return result["text"]
```

### 2. Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ

#### Ø£) Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Levenshtein
```python
def levenshtein_distance(str1, str2):
    """
    Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¨ÙŠÙ† Ù†ØµÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Levenshtein
    """
    if len(str1) < len(str2):
        return levenshtein_distance(str2, str1)

    if len(str2) == 0:
        return len(str1)

    previous_row = list(range(len(str2) + 1))
    for i, c1 in enumerate(str1):
        current_row = [i + 1]
        for j, c2 in enumerate(str2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row

    return previous_row[-1]

def calculate_similarity(text1, text2):
    """
    Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø¨ÙŠÙ† Ù†ØµÙŠÙ†
    """
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
    text1 = text1.strip().lower()
    text2 = text2.strip().lower()
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ©
    distance = levenshtein_distance(text1, text2)
    max_length = max(len(text1), len(text2))
    
    # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚
    if max_length == 0:
        return 100.0
    
    similarity = ((max_length - distance) / max_length) * 100
    return round(similarity, 2)

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
text1 = "Ø£Ø±Ù†Ø¨"
text2 = "Ø£Ø±Ù†Ø¨"
similarity = calculate_similarity(text1, text2)  # 100.0

text1 = "Ø£Ø±Ù†Ø¨"
text2 = "Ø±Ù†Ø¨"
similarity = calculate_similarity(text1, text2)  # 75.0
```

#### Ø¨) ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
```python
def analyze_characters_advanced(target_word, user_pronunciation, target_char):
    """
    ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø­Ø±ÙˆÙ Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø®ØµÙˆØµÙŠØ§Øª Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    """
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
    target_word = target_word.strip()
    user_pronunciation = user_pronunciation.strip()
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ù…ÙˆØ§Ø¶Ø¹ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
    target_positions = [i for i, char in enumerate(target_word) if char == target_char]
    
    if not target_positions:
        return {
            "found": False,
            "message": f"Ø§Ù„Ø­Ø±Ù '{target_char}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©",
            "target_positions": [],
            "user_positions": []
        }
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø­Ø±Ù ÙÙŠ Ù†Ø·Ù‚ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    user_positions = [i for i, char in enumerate(user_pronunciation) if char == target_char]
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    if not user_positions:
        return {
            "found": False,
            "message": f"Ù„Ù… ØªÙ†Ø·Ù‚ Ø§Ù„Ø­Ø±Ù '{target_char}' ÙÙŠ Ø£ÙŠ Ù…ÙˆØ¶Ø¹",
            "target_positions": target_positions,
            "user_positions": []
        }
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹
    correct_positions = []
    incorrect_positions = []
    
    for target_pos in target_positions:
        if target_pos < len(user_pronunciation) and user_pronunciation[target_pos] == target_char:
            correct_positions.append(target_pos)
        else:
            incorrect_positions.append(target_pos)
    
    # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†ØªÙŠØ¬Ø©
    accuracy = len(correct_positions) / len(target_positions) * 100
    
    return {
        "found": True,
        "accuracy": accuracy,
        "correct_positions": correct_positions,
        "incorrect_positions": incorrect_positions,
        "target_positions": target_positions,
        "user_positions": user_positions,
        "message": f"Ù†Ø·Ù‚Øª Ø§Ù„Ø­Ø±Ù '{target_char}' Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ ÙÙŠ {len(correct_positions)} Ù…Ù† {len(target_positions)} Ù…ÙˆØ¶Ø¹"
    }

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
target_word = "Ø£Ø±Ù†Ø¨"
user_pronunciation = "Ø£Ø±Ù†Ø¨"
target_char = "Ø£"

result = analyze_characters_advanced(target_word, user_pronunciation, target_char)
# Ø§Ù„Ù†ØªÙŠØ¬Ø©: {"found": True, "accuracy": 100.0, "correct_positions": [0], ...}
```

#### Ø¬) Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©
```python
def arabic_text_similarity(text1, text2):
    """
    Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù…Ù‚Ø§Ø±Ù†Ø© Ù†ØµÙˆØµ Ù…Ø­Ø³Ù†Ø© Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    """
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ (Ø§Ù„Ø­Ø±ÙƒØ§Øª)
    def remove_diacritics(text):
        diacritics = ['Ù', 'Ù', 'Ù', 'Ù‘', 'Ù’', 'Ù‹', 'ÙŒ', 'Ù', 'Ù°', 'Ù±']
        for diacritic in diacritics:
            text = text.replace(diacritic, '')
        return text
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ
    text1_clean = remove_diacritics(text1.strip())
    text2_clean = remove_diacritics(text2.strip())
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    basic_distance = levenshtein_distance(text1_clean, text2_clean)
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø©
    similar_chars = {
        'Ø£': ['Ø§', 'Ø¢', 'Ø¥'],
        'Ø§': ['Ø£', 'Ø¢', 'Ø¥'],
        'Ùˆ': ['Ø¤'],
        'ÙŠ': ['Ù‰', 'Ø¦'],
        'Ù‡': ['Ø©'],
        'Ø©': ['Ù‡']
    }
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
    enhanced_distance = calculate_enhanced_distance(text1_clean, text2_clean, similar_chars)
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø£Ù‚Ù„
    final_distance = min(basic_distance, enhanced_distance)
    max_length = max(len(text1_clean), len(text2_clean))
    
    if max_length == 0:
        return 100.0
    
    similarity = ((max_length - final_distance) / max_length) * 100
    return round(similarity, 2)

def calculate_enhanced_distance(text1, text2, similar_chars):
    """
    Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø©
    """
    if len(text1) < len(text2):
        return calculate_enhanced_distance(text2, text1)
    
    if len(text2) == 0:
        return len(text1)
    
    previous_row = list(range(len(text2) + 1))
    for i, c1 in enumerate(text1):
        current_row = [i + 1]
        for j, c2 in enumerate(text2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            
            # Ø­Ø³Ø§Ø¨ ØªÙƒÙ„ÙØ© Ø§Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø©
            substitution_cost = 0 if c1 == c2 else 1
            if c1 in similar_chars and c2 in similar_chars[c1]:
                substitution_cost = 0.5  # ØªÙƒÙ„ÙØ© Ø£Ù‚Ù„ Ù„Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ù…ØªØ´Ø§Ø¨Ù‡Ø©
            
            substitutions = previous_row[j] + substitution_cost
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row
    
    return previous_row[-1]

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
text1 = "Ø£ÙØ±Ù’Ù†ÙØ¨"
text2 = "Ø§Ø±Ù†Ø¨"
similarity = arabic_text_similarity(text1, text2)  # 100.0 (Ù…Ø¹ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„)

text1 = "Ø£Ø±Ù†Ø¨"
text2 = "Ø§Ø±Ù†Ø¨"
similarity = arabic_text_similarity(text1, text2)  # 100.0 (Ø§Ù„Ø­Ø±ÙˆÙ Ù…ØªØ´Ø§Ø¨Ù‡Ø©)
```

### 3. Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø§Øª ÙˆØ§Ù„Ø£Ù…Ø§Ù†

#### Ø£) Ø­Ù…Ø§ÙŠØ© Ø¶Ø¯ Ù‡Ø¬Ù…Ø§Øª Brute Force
```python
import redis
from datetime import timedelta
from django.utils import timezone

class SecurityManager:
    def __init__(self):
        self.redis_client = redis.StrictRedis.from_url('redis://localhost:6379/0')
        self.MAX_ATTEMPTS = 3
        self.LOCKOUT_DURATION = 3600  # Ø³Ø§Ø¹Ø© ÙˆØ§Ø­Ø¯Ø©
        self.VERIFICATION_EXPIRY = 600  # 10 Ø¯Ù‚Ø§Ø¦Ù‚
    
    def check_failed_attempts(self, email, username):
        """
        ÙØ­Øµ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø© ÙˆØ­Ù…Ø§ÙŠØ© Ø¶Ø¯ Ø§Ù„Ù‡Ø¬Ù…Ø§Øª
        """
        attempt_key = f"failed_attempts:{email}:{username}"
        lockout_key = f"lockout:{email}:{username}"
        
        # ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø¸Ø±
        if self.redis_client.exists(lockout_key):
            remaining_time = self.redis_client.ttl(lockout_key)
            return {
                "allowed": False,
                "message": f"ØªÙ… Ø­Ø¸Ø± Ø§Ù„Ø­Ø³Ø§Ø¨ Ù…Ø¤Ù‚ØªØ§Ù‹. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¨Ø¹Ø¯ {remaining_time} Ø«Ø§Ù†ÙŠØ©",
                "remaining_time": remaining_time
            }
        
        # ÙØ­Øµ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
        failed_attempts = self.redis_client.get(attempt_key)
        if failed_attempts and int(failed_attempts) >= self.MAX_ATTEMPTS:
            # ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø­Ø¸Ø±
            self.redis_client.setex(lockout_key, self.LOCKOUT_DURATION, "locked")
            return {
                "allowed": False,
                "message": f"ØªÙ… Ø­Ø¸Ø± Ø§Ù„Ø­Ø³Ø§Ø¨ Ù„Ù…Ø¯Ø© Ø³Ø§Ø¹Ø© ÙˆØ§Ø­Ø¯Ø© Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©",
                "remaining_time": self.LOCKOUT_DURATION
            }
        
        return {"allowed": True, "message": "ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©"}
    
    def increment_failed_attempts(self, email, username):
        """
        Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø©
        """
        attempt_key = f"failed_attempts:{email}:{username}"
        self.redis_client.incr(attempt_key)
        self.redis_client.expire(attempt_key, self.LOCKOUT_DURATION)
    
    def reset_failed_attempts(self, email, username):
        """
        Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø©
        """
        attempt_key = f"failed_attempts:{email}:{username}"
        lockout_key = f"lockout:{email}:{username}"
        self.redis_client.delete(attempt_key, lockout_key)

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙŠ views.py
security_manager = SecurityManager()

class VerifyEmailView(APIView):
    def post(self, request):
        email = request.data.get("email")
        username = request.data.get("username")
        verification_code = request.data.get("verification_code")
        
        # ÙØ­Øµ Ø§Ù„Ø£Ù…Ø§Ù†
        security_check = security_manager.check_failed_attempts(email, username)
        if not security_check["allowed"]:
            return Response({
                "error": security_check["message"]
            }, status=status.HTTP_429_TOO_MANY_REQUESTS)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙƒÙˆØ¯
        user = get_user_model().objects.filter(email=email, username=username).first()
        if not user or user.verification_code != verification_code:
            security_manager.increment_failed_attempts(email, username)
            return Response({
                "error": "Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚ ØºÙŠØ± ØµØ­ÙŠØ­"
            }, status=status.HTTP_400_BAD_REQUEST)
        
        # Ù†Ø¬Ø­ Ø§Ù„ØªØ­Ù‚Ù‚
        security_manager.reset_failed_attempts(email, username)
        user.is_active = True
        user.save()
        
        return Response({
            "message": "ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ù†Ø¬Ø§Ø­"
        }, status=status.HTTP_200_OK)
```

#### Ø¨) Ø¥Ø¯Ø§Ø±Ø© Ø±Ù…ÙˆØ² Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
```python
import secrets
import hashlib
from datetime import timedelta
from django.utils import timezone

class VerificationCodeManager:
    def __init__(self):
        self.CODE_LENGTH = 8
        self.EXPIRY_MINUTES = 10
        self.MAX_CODES_PER_HOUR = 5
    
    def generate_verification_code(self):
        """
        ØªÙˆÙ„ÙŠØ¯ Ø±Ù…Ø² ØªØ­Ù‚Ù‚ Ø¢Ù…Ù†
        """
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… secrets Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† random Ù„Ù„Ø£Ù…Ø§Ù†
        return ''.join(secrets.choice('0123456789') for _ in range(self.CODE_LENGTH))
    
    def generate_secure_code(self):
        """
        ØªÙˆÙ„ÙŠØ¯ Ø±Ù…Ø² ØªØ­Ù‚Ù‚ Ø£ÙƒØ«Ø± Ø£Ù…Ø§Ù†Ø§Ù‹ Ù…Ø¹ hash
        """
        code = self.generate_verification_code()
        # Ø¥Ø¶Ø§ÙØ© timestamp Ù„Ù„Ø±Ù…Ø²
        timestamp = str(int(timezone.now().timestamp()))
        code_with_timestamp = f"{code}_{timestamp}"
        
        # Ø¥Ù†Ø´Ø§Ø¡ hash Ù„Ù„Ø±Ù…Ø²
        code_hash = hashlib.sha256(code_with_timestamp.encode()).hexdigest()[:16]
        
        return {
            "code": code,
            "hash": code_hash,
            "timestamp": timestamp
        }
    
    def is_verification_code_expired(self, sent_at):
        """
        ÙØ­Øµ Ø§Ù†ØªÙ‡Ø§Ø¡ ØµÙ„Ø§Ø­ÙŠØ© Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚
        """
        if not sent_at:
            return True
        
        expiry_time = sent_at + timedelta(minutes=self.EXPIRY_MINUTES)
        return timezone.now() > expiry_time
    
    def validate_code_rate_limit(self, email):
        """
        ÙØ­Øµ Ø­Ø¯ Ø¹Ø¯Ø¯ Ø±Ù…ÙˆØ² Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…Ø±Ø³Ù„Ø©
        """
        rate_key = f"verification_rate:{email}"
        current_count = redis_client.get(rate_key)
        
        if current_count and int(current_count) >= self.MAX_CODES_PER_HOUR:
            return False
        
        return True
    
    def increment_code_count(self, email):
        """
        Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø§Ø¯ Ø±Ù…ÙˆØ² Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ù…Ø±Ø³Ù„Ø©
        """
        rate_key = f"verification_rate:{email}"
        redis_client.incr(rate_key)
        redis_client.expire(rate_key, 3600)  # Ø³Ø§Ø¹Ø© ÙˆØ§Ø­Ø¯Ø©

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
verification_manager = VerificationCodeManager()

class RegisterView(APIView):
    def post(self, request):
        email = request.data.get("email")
        
        # ÙØ­Øµ Ø­Ø¯ Ø¥Ø±Ø³Ø§Ù„ Ø±Ù…ÙˆØ² Ø§Ù„ØªØ­Ù‚Ù‚
        if not verification_manager.validate_code_rate_limit(email):
            return Response({
                "error": "ØªÙ… ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØªØ­Ù‚Ù‚. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¨Ø¹Ø¯ Ø³Ø§Ø¹Ø©"
            }, status=status.HTTP_429_TOO_MANY_REQUESTS)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø±Ù…Ø² ØªØ­Ù‚Ù‚ Ø¢Ù…Ù†
        secure_code = verification_manager.generate_secure_code()
        
        # Ø­ÙØ¸ Ø§Ù„Ø±Ù…Ø² ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        user = User.objects.create(
            email=email,
            verification_code=secure_code["code"],
            verification_code_sent_at=timezone.now()
        )
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø±Ù…Ø² Ø¹Ø¨Ø± Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
        send_verification_email.delay(email, secure_code["code"])
        
        # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ø±Ø³Ù„Ø©
        verification_manager.increment_code_count(email)
        
        return Response({
            "message": "ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ù„Ù‰ Ø¨Ø±ÙŠØ¯Ùƒ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ"
        }, status=status.HTTP_201_CREATED)
```

#### Ø¬) Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ø¢Ù…Ù†Ø©
```python
import jwt
from datetime import datetime, timedelta
from django.conf import settings

class SessionManager:
    def __init__(self):
        self.SECRET_KEY = settings.SECRET_KEY
        self.ALGORITHM = "HS256"
        self.ACCESS_TOKEN_EXPIRE_MINUTES = 30
        self.REFRESH_TOKEN_EXPIRE_DAYS = 7
    
    def create_access_token(self, data: dict):
        """
        Ø¥Ù†Ø´Ø§Ø¡ token Ù„Ù„ÙˆØµÙˆÙ„
        """
        to_encode = data.copy()
        expire = datetime.utcnow() + timedelta(minutes=self.ACCESS_TOKEN_EXPIRE_MINUTES)
        to_encode.update({"exp": expire})
        encoded_jwt = jwt.encode(to_encode, self.SECRET_KEY, algorithm=self.ALGORITHM)
        return encoded_jwt
    
    def create_refresh_token(self, data: dict):
        """
        Ø¥Ù†Ø´Ø§Ø¡ token Ù„Ù„ØªØ¬Ø¯ÙŠØ¯
        """
        to_encode = data.copy()
        expire = datetime.utcnow() + timedelta(days=self.REFRESH_TOKEN_EXPIRE_DAYS)
        to_encode.update({"exp": expire, "type": "refresh"})
        encoded_jwt = jwt.encode(to_encode, self.SECRET_KEY, algorithm=self.ALGORITHM)
        return encoded_jwt
    
    def verify_token(self, token: str):
        """
        Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© token
        """
        try:
            payload = jwt.decode(token, self.SECRET_KEY, algorithms=[self.ALGORITHM])
            return payload
        except jwt.ExpiredSignatureError:
            return {"error": "Token Ù…Ù†ØªÙ‡ÙŠ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©"}
        except jwt.JWTError:
            return {"error": "Token ØºÙŠØ± ØµØ­ÙŠØ­"}
    
    def blacklist_token(self, token: str):
        """
        Ø¥Ø¶Ø§ÙØ© token Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡
        """
        blacklist_key = f"blacklist:{token}"
        redis_client.setex(blacklist_key, self.ACCESS_TOKEN_EXPIRE_MINUTES * 60, "blacklisted")
    
    def is_token_blacklisted(self, token: str):
        """
        ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† token ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡
        """
        blacklist_key = f"blacklist:{token}"
        return redis_client.exists(blacklist_key)

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
session_manager = SessionManager()

class LoginView(APIView):
    def post(self, request):
        username = request.data.get("username")
        password = request.data.get("password")
        
        user = authenticate(username=username, password=password)
        if not user:
            return Response({
                "error": "Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ø®ÙˆÙ„ ØºÙŠØ± ØµØ­ÙŠØ­Ø©"
            }, status=status.HTTP_401_UNAUTHORIZED)
        
        # Ø¥Ù†Ø´Ø§Ø¡ tokens
        access_token = session_manager.create_access_token(
            data={"sub": user.username, "user_id": user.id}
        )
        refresh_token = session_manager.create_refresh_token(
            data={"sub": user.username, "user_id": user.id}
        )
        
        return Response({
            "access_token": access_token,
            "refresh_token": refresh_token,
            "token_type": "bearer"
        }, status=status.HTTP_200_OK)

class LogoutView(APIView):
    def post(self, request):
        # Ø¥Ø¶Ø§ÙØ© token Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡
        auth_header = request.headers.get('Authorization')
        if auth_header and auth_header.startswith('Bearer '):
            token = auth_header.split(' ')[1]
            session_manager.blacklist_token(token)
        
        return Response({
            "message": "ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø±ÙˆØ¬ Ø¨Ù†Ø¬Ø§Ø­"
        }, status=status.HTTP_200_OK)
```

## Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

### 1. Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Models)

#### Ø£) Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
```python
from django.contrib.auth.models import AbstractUser
from django.core.exceptions import ValidationError
from django.db import models
from django.db.models import Q
from django.db.models.signals import pre_save
from django.dispatch import receiver
from django.utils import timezone
from datetime import timedelta

class CustomUser(AbstractUser):
    """
    Ù†Ù…ÙˆØ°Ø¬ Ù…Ø³ØªØ®Ø¯Ù… Ù…Ø®ØµØµ Ù…Ø¹ Ù…ÙŠØ²Ø§Øª Ø£Ù…Ø§Ù† Ù…ØªÙ‚Ø¯Ù…Ø©
    """
    email = models.EmailField(unique=True, verbose_name="Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ")
    verification_code = models.CharField(
        max_length=8, 
        blank=True, 
        null=True,
        verbose_name="Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚"
    )
    failed_attempts = models.IntegerField(
        default=0,
        verbose_name="Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø©"
    )
    verification_code_sent_at = models.DateTimeField(
        null=True, 
        blank=True,
        verbose_name="ÙˆÙ‚Øª Ø¥Ø±Ø³Ø§Ù„ Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚"
    )
    last_login_ip = models.GenericIPAddressField(
        null=True, 
        blank=True,
        verbose_name="Ø¢Ø®Ø± Ø¹Ù†ÙˆØ§Ù† IP"
    )
    is_email_verified = models.BooleanField(
        default=False,
        verbose_name="ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ"
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡"
    )
    updated_at = models.DateTimeField(
        auto_now=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ø¯ÙŠØ«"
    )

    class Meta:
        constraints = [
            models.UniqueConstraint(
                fields=["email"],
                name="unique_email_active",
                condition=Q(is_active=True),
            )
        ]
        verbose_name = "Ù…Ø³ØªØ®Ø¯Ù…"
        verbose_name_plural = "Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"

    def clean(self):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        if self.is_active:
            if (
                CustomUser.objects.filter(email=self.email, is_active=True)
                .exclude(id=self.id)
                .exists()
            ):
                raise ValidationError(
                    f"ÙŠÙˆØ¬Ø¯ Ù…Ø³ØªØ®Ø¯Ù… Ù†Ø´Ø· Ø¨Ù†ÙØ³ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ: {self.email}"
                )

    def is_verification_code_expired(self):
        """ÙØ­Øµ Ø§Ù†ØªÙ‡Ø§Ø¡ ØµÙ„Ø§Ø­ÙŠØ© Ø±Ù…Ø² Ø§Ù„ØªØ­Ù‚Ù‚"""
        if self.verification_code_sent_at:
            return timezone.now() > self.verification_code_sent_at + timedelta(minutes=10)
        return True

    def increment_failed_attempts(self):
        """Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø©"""
        self.failed_attempts += 1
        self.save(update_fields=['failed_attempts'])

    def reset_failed_attempts(self):
        """Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø©"""
        self.failed_attempts = 0
        self.save(update_fields=['failed_attempts'])

    def __str__(self):
        return f"{self.username} ({self.email})"

# Signal Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ØºÙŠØ± Ø§Ù„Ù†Ø´Ø·ÙŠÙ†
@receiver(pre_save, sender=CustomUser)
def deactivate_other_users_with_same_email(sender, instance, **kwargs):
    """Ø¥Ù„ØºØ§Ø¡ ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø¢Ø®Ø±ÙŠÙ† Ø¨Ù†ÙØ³ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ"""
    if instance.is_active:
        CustomUser.objects.filter(
            email=instance.email, 
            is_active=False
        ).delete()
```

#### Ø¨) Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
```python
class Language(models.Model):
    """
    Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ© Ù…Ø¹ Ø¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª
    """
    LANGUAGE_CHOICES = [
        ("ar", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"),
        ("en", "English"),
        ("fr", "FranÃ§ais"),
        ("es", "EspaÃ±ol"),
        ("de", "Deutsch"),
    ]

    code = models.CharField(
        max_length=2, 
        choices=LANGUAGE_CHOICES, 
        unique=True,
        verbose_name="Ø±Ù…Ø² Ø§Ù„Ù„ØºØ©"
    )
    name = models.CharField(
        max_length=50,
        verbose_name="Ø§Ø³Ù… Ø§Ù„Ù„ØºØ©"
    )
    native_name = models.CharField(
        max_length=50,
        blank=True,
        verbose_name="Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø£ØµÙ„ÙŠ"
    )
    is_active = models.BooleanField(
        default=True,
        verbose_name="Ù†Ø´Ø·"
    )
    is_default = models.BooleanField(
        default=False,
        verbose_name="Ø§Ù„Ù„ØºØ© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©"
    )
    direction = models.CharField(
        max_length=3,
        choices=[("ltr", "Left to Right"), ("rtl", "Right to Left")],
        default="ltr",
        verbose_name="Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ÙƒØªØ§Ø¨Ø©"
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡"
    )
    updated_at = models.DateTimeField(
        auto_now=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ø¯ÙŠØ«"
    )

    class Meta:
        ordering = ["code"]
        verbose_name = "Ù„ØºØ©"
        verbose_name_plural = "Ø§Ù„Ù„ØºØ§Øª"

    def save(self, *args, **kwargs):
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©"""
        if self.is_default:
            # Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…Ù† Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ø£Ø®Ø±Ù‰
            Language.objects.filter(is_default=True).update(is_default=False)
        super().save(*args, **kwargs)

    def __str__(self):
        return f"{self.name} ({self.code})"

    @property
    def is_rtl(self):
        """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù„ØºØ© Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ù„Ù„ÙŠØ³Ø§Ø±"""
        return self.direction == "rtl"
```

#### Ø¬) Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
```python
class Letter(models.Model):
    """
    Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø±Ù Ù…Ø¹ Ø¯Ø¹Ù… Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ÙˆØ³Ø§Ø¦Ø·
    """
    language = models.ForeignKey(
        Language, 
        on_delete=models.CASCADE, 
        related_name="letters",
        verbose_name="Ø§Ù„Ù„ØºØ©"
    )
    letter = models.CharField(
        max_length=10,
        verbose_name="Ø§Ù„Ø­Ø±Ù"
    )
    word = models.CharField(
        max_length=100,
        verbose_name="Ø§Ù„ÙƒÙ„Ù…Ø©"
    )
    color = models.CharField(
        max_length=50, 
        default="bg-blue-300",
        verbose_name="Ø§Ù„Ù„ÙˆÙ†"
    )
    box_color = models.CharField(
        max_length=50, 
        default="bg-blue-400",
        verbose_name="Ù„ÙˆÙ† Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚"
    )
    word_image = models.URLField(
        max_length=500, 
        blank=True, 
        null=True,
        verbose_name="ØµÙˆØ±Ø© Ø§Ù„ÙƒÙ„Ù…Ø©"
    )
    audio_file = models.FileField(
        upload_to="letters/audio/", 
        blank=True, 
        null=True,
        verbose_name="Ù…Ù„Ù Ø§Ù„ØµÙˆØª"
    )
    is_active = models.BooleanField(
        default=True,
        verbose_name="Ù†Ø´Ø·"
    )
    order = models.PositiveIntegerField(
        default=0,
        verbose_name="Ø§Ù„ØªØ±ØªÙŠØ¨"
    )
    difficulty_level = models.CharField(
        max_length=20,
        choices=[
            ("beginner", "Ù…Ø¨ØªØ¯Ø¦"),
            ("intermediate", "Ù…ØªÙˆØ³Ø·"),
            ("advanced", "Ù…ØªÙ‚Ø¯Ù…"),
        ],
        default="beginner",
        verbose_name="Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµØ¹ÙˆØ¨Ø©"
    )
    phonetic_transcription = models.CharField(
        max_length=100,
        blank=True,
        verbose_name="Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„ØµÙˆØªÙŠ"
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡"
    )
    updated_at = models.DateTimeField(
        auto_now=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ø¯ÙŠØ«"
    )

    class Meta:
        unique_together = ["language", "letter"]
        ordering = ["language", "order", "letter"]
        verbose_name = "Ø­Ø±Ù"
        verbose_name_plural = "Ø§Ù„Ø­Ø±ÙˆÙ"

    def __str__(self):
        return f"{self.language.code.upper()}: {self.letter} - {self.word}"

    @property
    def media_url(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø§Ù„ÙˆØ³Ø§Ø¦Ø·"""
        if self.audio_file:
            return self.audio_file.url
        return f"/media/{self.word}.wav"

    def get_absolute_url(self):
        """Ø±Ø§Ø¨Ø· Ø§Ù„Ø­Ø±Ù"""
        return f"/api/{self.language.code}/letters/{self.letter}/"

    def get_levels_count(self):
        """Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ù„Ù„Ø­Ø±Ù"""
        return self.levels.filter(is_active=True).count()

    def get_average_difficulty(self):
        """Ù…ØªÙˆØ³Ø· ØµØ¹ÙˆØ¨Ø© Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª"""
        levels = self.levels.filter(is_active=True)
        if not levels:
            return 0
        
        difficulty_scores = {
            "easy": 1,
            "medium": 2,
            "hard": 3
        }
        
        total_score = sum(difficulty_scores.get(level.difficulty, 1) for level in levels)
        return total_score / len(levels)
```

#### Ø¯) Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
```python
class Level(models.Model):
    """
    Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ù…Ø¹ Ø¯Ø¹Ù… Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØªØ¹Ù„Ù…
    """
    language = models.ForeignKey(
        Language, 
        on_delete=models.CASCADE, 
        related_name="levels",
        verbose_name="Ø§Ù„Ù„ØºØ©"
    )
    letter = models.ForeignKey(
        Letter, 
        on_delete=models.CASCADE, 
        related_name="levels",
        verbose_name="Ø§Ù„Ø­Ø±Ù"
    )
    level_number = models.PositiveIntegerField(
        verbose_name="Ø±Ù‚Ù… Ø§Ù„Ù…Ø³ØªÙˆÙ‰"
    )
    test_word = models.CharField(
        max_length=100,
        verbose_name="Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ©"
    )
    word_image = models.URLField(
        max_length=500, 
        blank=True, 
        null=True,
        verbose_name="ØµÙˆØ±Ø© Ø§Ù„ÙƒÙ„Ù…Ø©"
    )
    audio_file = models.FileField(
        upload_to="levels/audio/", 
        blank=True, 
        null=True,
        verbose_name="Ù…Ù„Ù Ø§Ù„ØµÙˆØª"
    )
    is_active = models.BooleanField(
        default=True,
        verbose_name="Ù†Ø´Ø·"
    )
    difficulty = models.CharField(
        max_length=20,
        choices=[
            ("easy", "Ø³Ù‡Ù„"),
            ("medium", "Ù…ØªÙˆØ³Ø·"),
            ("hard", "ØµØ¹Ø¨"),
        ],
        default="easy",
        verbose_name="Ø§Ù„ØµØ¹ÙˆØ¨Ø©"
    )
    target_char_positions = models.JSONField(
        default=list,
        verbose_name="Ù…ÙˆØ§Ø¶Ø¹ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù"
    )
    alternative_words = models.JSONField(
        default=list,
        verbose_name="ÙƒÙ„Ù…Ø§Øª Ø¨Ø¯ÙŠÙ„Ø©"
    )
    hints = models.TextField(
        blank=True,
        verbose_name="Ù†ØµØ§Ø¦Ø­"
    )
    success_threshold = models.PositiveIntegerField(
        default=60,
        verbose_name="Ø­Ø¯ Ø§Ù„Ù†Ø¬Ø§Ø­ (%)"
    )
    time_limit = models.PositiveIntegerField(
        default=30,
        verbose_name="Ø§Ù„Ø­Ø¯ Ø§Ù„Ø²Ù…Ù†ÙŠ (Ø«Ø§Ù†ÙŠØ©)"
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡"
    )
    updated_at = models.DateTimeField(
        auto_now=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ø¯ÙŠØ«"
    )

    class Meta:
        unique_together = ["language", "letter", "level_number"]
        ordering = ["language", "letter", "level_number"]
        verbose_name = "Ù…Ø³ØªÙˆÙ‰"
        verbose_name_plural = "Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª"

    def __str__(self):
        return f"{self.language.code.upper()}: {self.letter.letter} Level {self.level_number} - {self.test_word}"

    @property
    def media_url(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø§Ù„ÙˆØ³Ø§Ø¦Ø·"""
        if self.audio_file:
            return self.audio_file.url
        return f"/media/{self.test_word}.wav"

    def get_absolute_url(self):
        """Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø³ØªÙˆÙ‰"""
        return f"/api/{self.language.code}/levels/{self.letter.letter}/{self.level_number}/"

    def get_target_char_positions(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ÙˆØ§Ø¶Ø¹ Ø§Ù„Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù"""
        if self.target_char_positions:
            return self.target_char_positions
        
        # Ø­Ø³Ø§Ø¨ Ù…ÙˆØ§Ø¶Ø¹ Ø§Ù„Ø­Ø±Ù ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        positions = []
        target_char = self.letter.letter
        for i, char in enumerate(self.test_word):
            if char == target_char:
                positions.append(i)
        
        # Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ§Ø¶Ø¹
        self.target_char_positions = positions
        self.save(update_fields=['target_char_positions'])
        
        return positions

    def get_next_level(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ"""
        return Level.objects.filter(
            language=self.language,
            letter=self.letter,
            level_number=self.level_number + 1,
            is_active=True
        ).first()

    def get_previous_level(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³Ø§Ø¨Ù‚"""
        return Level.objects.filter(
            language=self.language,
            letter=self.letter,
            level_number=self.level_number - 1,
            is_active=True
        ).first()

    def is_completed_by_user(self, user):
        """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£ÙƒÙ…Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³ØªÙˆÙ‰"""
        # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ù…Ù†Ø·Ù‚ ØªØªØ¨Ø¹ Ø§Ù„ØªÙ‚Ø¯Ù… Ù‡Ù†Ø§
        return False
```

### 2. Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆØ§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©

#### Ø£) Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
```python
# Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
Language (1) â†â†’ (N) Letter
Letter (1) â†â†’ (N) Level  
Language (1) â†â†’ (N) Level
CustomUser (1) â†â†’ (1) Profile
Skill (1) â†â†’ (N) Quiz
```

#### Ø¨) Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
```python
# Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

class LetterManager(models.Manager):
    """Ù…Ø¯ÙŠØ± Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø­Ø±ÙˆÙ"""
    
    def get_letters_with_levels_count(self, language_code):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ Ù…Ø¹ Ø¹Ø¯Ø¯ Ù…Ø³ØªÙˆÙŠØ§ØªÙ‡Ø§"""
        return self.filter(
            language__code=language_code,
            is_active=True
        ).annotate(
            levels_count=Count('levels', filter=Q(levels__is_active=True)),
            completed_levels=Count('levels', filter=Q(levels__is_active=True))
        ).order_by('order')
    
    def get_letters_by_difficulty(self, language_code, difficulty):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ Ø­Ø³Ø¨ Ø§Ù„ØµØ¹ÙˆØ¨Ø©"""
        return self.filter(
            language__code=language_code,
            is_active=True,
            difficulty_level=difficulty
        ).prefetch_related('levels').order_by('order')
    
    def get_letters_with_progress(self, user, language_code):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø±ÙˆÙ Ù…Ø¹ ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        return self.filter(
            language__code=language_code,
            is_active=True
        ).annotate(
            total_levels=Count('levels', filter=Q(levels__is_active=True)),
            completed_levels=Count(
                'levels',
                filter=Q(
                    levels__is_active=True,
                    levels__userprogress__user=user,
                    levels__userprogress__is_completed=True
                )
            )
        ).order_by('order')

class LevelManager(models.Manager):
    """Ù…Ø¯ÙŠØ± Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ø³ØªÙˆÙŠØ§Øª"""
    
    def get_levels_with_details(self, language_code, letter):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª Ù…Ø¹ Ø§Ù„ØªÙØ§ØµÙŠÙ„"""
        return self.filter(
            language__code=language_code,
            letter__letter=letter,
            is_active=True
        ).select_related('letter', 'language').order_by('level_number')
    
    def get_next_available_level(self, user, language_code, letter, current_level):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ Ø§Ù„Ù…ØªØ§Ø­"""
        return self.filter(
            language__code=language_code,
            letter__letter=letter,
            level_number__gt=current_level,
            is_active=True
        ).exclude(
            userprogress__user=user,
            userprogress__is_completed=False
        ).order_by('level_number').first()
    
    def get_user_progress(self, user, language_code):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        return self.filter(
            language__code=language_code,
            userprogress__user=user
        ).annotate(
            is_completed=Max('userprogress__is_completed'),
            completion_date=Max('userprogress__completed_at'),
            attempts_count=Count('userprogress'),
            best_score=Max('userprogress__score')
        ).order_by('letter__order', 'level_number')

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¯ÙŠØ±ÙŠÙ† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…ÙŠÙ†
class Letter(models.Model):
    # ... Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ...
    objects = LetterManager()

class Level(models.Model):
    # ... Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ...
    objects = LevelManager()
```

#### Ø¬) Ù†Ù…Ø§Ø°Ø¬ Ø¥Ø¶Ø§ÙÙŠØ© Ù„ØªØªØ¨Ø¹ Ø§Ù„ØªÙ‚Ø¯Ù…
```python
class UserProgress(models.Model):
    """ØªØªØ¨Ø¹ ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    user = models.ForeignKey(
        CustomUser, 
        on_delete=models.CASCADE,
        related_name='progress',
        verbose_name="Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"
    )
    level = models.ForeignKey(
        Level, 
        on_delete=models.CASCADE,
        related_name='userprogress',
        verbose_name="Ø§Ù„Ù…Ø³ØªÙˆÙ‰"
    )
    is_completed = models.BooleanField(
        default=False,
        verbose_name="Ù…ÙƒØªÙ…Ù„"
    )
    score = models.PositiveIntegerField(
        default=0,
        verbose_name="Ø§Ù„Ø¯Ø±Ø¬Ø©"
    )
    attempts_count = models.PositiveIntegerField(
        default=0,
        verbose_name="Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª"
    )
    best_pronunciation_score = models.FloatField(
        default=0.0,
        verbose_name="Ø£ÙØ¶Ù„ Ø¯Ø±Ø¬Ø© Ù†Ø·Ù‚"
    )
    time_spent = models.PositiveIntegerField(
        default=0,
        verbose_name="Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø³ØªØºØ±Ù‚ (Ø«Ø§Ù†ÙŠØ©)"
    )
    completed_at = models.DateTimeField(
        null=True, 
        blank=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥ÙƒÙ…Ø§Ù„"
    )
    created_at = models.DateTimeField(
        auto_now_add=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡"
    )
    updated_at = models.DateTimeField(
        auto_now=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ø¯ÙŠØ«"
    )

    class Meta:
        unique_together = ['user', 'level']
        verbose_name = "ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"
        verbose_name_plural = "ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"

    def __str__(self):
        return f"{self.user.username} - {self.level}"

    def update_progress(self, score, pronunciation_score, time_spent):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù…"""
        self.attempts_count += 1
        self.score = max(self.score, score)
        self.best_pronunciation_score = max(self.best_pronunciation_score, pronunciation_score)
        self.time_spent += time_spent
        
        if score >= self.level.success_threshold:
            self.is_completed = True
            self.completed_at = timezone.now()
        
        self.save()

class UserAchievement(models.Model):
    """Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
    user = models.ForeignKey(
        CustomUser, 
        on_delete=models.CASCADE,
        related_name='achievements',
        verbose_name="Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"
    )
    achievement_type = models.CharField(
        max_length=50,
        choices=[
            ('first_level', 'Ø£ÙˆÙ„ Ù…Ø³ØªÙˆÙ‰'),
            ('perfect_score', 'Ø¯Ø±Ø¬Ø© Ù…Ø«Ø§Ù„ÙŠØ©'),
            ('speed_learner', 'Ù…ØªØ¹Ù„Ù… Ø³Ø±ÙŠØ¹'),
            ('persistent', 'Ù…Ø«Ø§Ø¨Ø±'),
            ('language_master', 'Ø³ÙŠØ¯ Ø§Ù„Ù„ØºØ©'),
        ],
        verbose_name="Ù†ÙˆØ¹ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"
    )
    description = models.TextField(
        verbose_name="ÙˆØµÙ Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²"
    )
    earned_at = models.DateTimeField(
        auto_now_add=True,
        verbose_name="ØªØ§Ø±ÙŠØ® Ø§Ù„Ø­ØµÙˆÙ„"
    )

    class Meta:
        unique_together = ['user', 'achievement_type']
        verbose_name = "Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"
        verbose_name_plural = "Ø¥Ù†Ø¬Ø§Ø²Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†"

    def __str__(self):
        return f"{self.user.username} - {self.get_achievement_type_display()}"
```

#### Ø¯) Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©
```python
# Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ù„Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…
class AnalyticsManager:
    """Ù…Ø¯ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
    
    @staticmethod
    def get_user_statistics(user):
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        progress = UserProgress.objects.filter(user=user)
        
        return {
            'total_levels_attempted': progress.count(),
            'completed_levels': progress.filter(is_completed=True).count(),
            'total_score': progress.aggregate(Sum('score'))['score__sum'] or 0,
            'average_score': progress.aggregate(Avg('score'))['score__avg'] or 0,
            'total_time_spent': progress.aggregate(Sum('time_spent'))['time_spent__sum'] or 0,
            'total_attempts': progress.aggregate(Sum('attempts_count'))['attempts_count__sum'] or 0,
            'achievements_count': user.achievements.count(),
        }
    
    @staticmethod
    def get_language_statistics(language_code):
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù„ØºØ©"""
        letters = Letter.objects.filter(language__code=language_code, is_active=True)
        levels = Level.objects.filter(language__code=language_code, is_active=True)
        
        return {
            'total_letters': letters.count(),
            'total_levels': levels.count(),
            'easy_levels': levels.filter(difficulty='easy').count(),
            'medium_levels': levels.filter(difficulty='medium').count(),
            'hard_levels': levels.filter(difficulty='hard').count(),
            'active_users': UserProgress.objects.filter(
                level__language__code=language_code
            ).values('user').distinct().count(),
        }
    
    @staticmethod
    def get_global_statistics():
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©"""
        return {
            'total_users': CustomUser.objects.filter(is_active=True).count(),
            'total_progress_records': UserProgress.objects.count(),
            'total_completed_levels': UserProgress.objects.filter(is_completed=True).count(),
            'total_achievements': UserAchievement.objects.count(),
            'most_popular_language': UserProgress.objects.values(
                'level__language__name'
            ).annotate(
                count=Count('id')
            ).order_by('-count').first(),
        }

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
analytics = AnalyticsManager()
user_stats = analytics.get_user_statistics(user)
language_stats = analytics.get_language_statistics('ar')
global_stats = analytics.get_global_statistics()
```

## Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„Ø­Ù…Ø§ÙŠØ©

### 1. Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

#### Ø£) ØªØ´ÙÙŠØ± ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙˆØ±
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Django's built-in password hashing
- ØªØ´ÙÙŠØ± Ù‚ÙˆÙŠ Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙˆØ±
- Ø­Ù…Ø§ÙŠØ© Ø¶Ø¯ Ù‡Ø¬Ù…Ø§Øª Ø§Ù„Ù‚ÙˆØ© Ø§Ù„ØºØ§Ø´Ù…Ø©

#### Ø¨) Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø¬Ù„Ø³Ø§Øª
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Django Sessions
- Ø¥Ø¯Ø§Ø±Ø© Ø¢Ù…Ù†Ø© Ù„Ù„Ø¬Ù„Ø³Ø§Øª
- Ø­Ù…Ø§ÙŠØ© Ø¶Ø¯ Ù‡Ø¬Ù…Ø§Øª CSRF

### 2. Ø­Ù…Ø§ÙŠØ© API

#### Ø£) Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©
- Token-based Authentication
- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØªÙˆÙƒÙ†
- Ø¥Ø¯Ø§Ø±Ø© Ø¢Ù…Ù†Ø© Ù„Ù„Ø¬Ù„Ø³Ø§Øª

#### Ø¨) Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„
- ØµÙ„Ø§Ø­ÙŠØ§Øª Ù…Ø®ØªÙ„ÙØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
- Ø­Ù…Ø§ÙŠØ© Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‡ÙˆÙŠØ©

### 3. Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ù…Ù„ÙØ§Øª

#### Ø£) Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
- ØªØ­Ø¯ÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
- Ø­Ù…Ø§ÙŠØ© Ø¶Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¶Ø§Ø±Ø©

#### Ø¨) ØªØ®Ø²ÙŠÙ† Ø¢Ù…Ù†
- ØªØ®Ø²ÙŠÙ† Ø¢Ù…Ù† Ù„Ù„Ù…Ù„ÙØ§Øª
- Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ø§Ù„ÙˆØµÙˆÙ„ ØºÙŠØ± Ø§Ù„Ù…ØµØ±Ø­
- Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù†ØªØ¸Ù…Ø©

## Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†

### 1. ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

#### Ø£) Ø§Ù„ÙÙ‡Ø§Ø±Ø³ (Indexes)
- ÙÙ‡Ø§Ø±Ø³ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©
- ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø¨Ø­Ø«
- ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

#### Ø¨) Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Redis Ù„Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
- ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
- ØªØ­Ø³ÙŠÙ† Ø³Ø±Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©

### 2. ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©

#### Ø£) ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØ³ÙˆÙ„ (Lazy Loading)
- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
- ØªØ­Ø³ÙŠÙ† Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„
- ØªÙ‚Ù„ÙŠÙ„ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±Ø©

#### Ø¨) ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±
- Ø¶ØºØ· Ø§Ù„ØµÙˆØ±
- Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø­Ø¯ÙŠØ«Ø©
- ØªØ­Ø³ÙŠÙ† Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„

### 3. ØªØ­Ø³ÙŠÙ† Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª

#### Ø£) Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ©
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Celery Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø®Ù„ÙÙŠØ©
- Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ© Ù„Ù„ØµÙˆØª
- ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡

#### Ø¨) ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Whisper Ø§Ù„Ù…Ø­Ø³Ù†
- ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
- ØªÙ‚Ù„ÙŠÙ„ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©

## Ø§Ù„Ù†Ø´Ø± ÙˆØ§Ù„ØªØ´ØºÙŠÙ„

### 1. Ø¥Ø¹Ø¯Ø§Ø¯ Docker

#### Ø£) Dockerfile Ù„Ù„Ø¨Ø§Ùƒ Ø¥Ù†Ø¯
```dockerfile
FROM python:3.11-slim
WORKDIR /code
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["python", "manage.py", "runserver", "0.0.0.0:8000"]
```

#### Ø¨) Dockerfile Ù„Ù„ÙØ±ÙˆÙ†Øª Ø¥Ù†Ø¯
```dockerfile
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
EXPOSE 5173
CMD ["npm", "run", "dev"]
```

### 2. Docker Compose

#### Ø£) Ø§Ù„Ø®Ø¯Ù…Ø§Øª
- **database**: MySQL 8.0
- **backend**: Django Application
- **frontend**: React Application
- **redis**: Redis Cache
- **celery**: Background Tasks
- **phpmyadmin**: Database Management

#### Ø¨) Ø§Ù„Ø´Ø¨ÙƒØ©
- Ø´Ø¨ÙƒØ© Ø¯Ø§Ø®Ù„ÙŠØ© Ù„Ù„Ø®Ø¯Ù…Ø§Øª
- Ù…Ù†Ø§ÙØ° Ù…Ø®ØµØµØ© Ù„ÙƒÙ„ Ø®Ø¯Ù…Ø©
- Ø§ØªØµØ§Ù„ Ø¢Ù…Ù† Ø¨ÙŠÙ† Ø§Ù„Ø®Ø¯Ù…Ø§Øª

### 3. Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©

#### Ø£) Ù…ØªØºÙŠØ±Ø§Øª Django
```env
SECRET_KEY=your-secret-key
DEBUG=True
DB_ENGINE=django.db.backends.mysql
DB_NAME=pronunciation_db
DB_USER=django
DB_PASSWORD=django123
```

#### Ø¨) Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
```env
EMAIL_HOST_USER=your-email@gmail.com
EMAIL_HOST_PASSWORD=your-app-password
```

## Ø§Ù„ØµÙŠØ§Ù†Ø© ÙˆØ§Ù„Ø¯Ø¹Ù…

### 1. Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©

#### Ø£) Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙŠÙˆÙ…ÙŠØ©
- ØªØ®Ø²ÙŠÙ† Ø¢Ù…Ù† Ù„Ù„Ù†Ø³Ø®
- Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ø³ØªØ¹Ø§Ø¯Ø©

#### Ø¨) Ø§Ù„Ù…Ù„ÙØ§Øª
- Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ù„Ù…Ù„ÙØ§Øª
- Ø­Ù…Ø§ÙŠØ© Ù…Ù† ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ø³ØªØ¹Ø§Ø¯Ø©

### 2. Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©

#### Ø£) Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡
- Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø®Ø§Ø¯Ù…
- Ù…Ø±Ø§Ù‚Ø¨Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø©

#### Ø¨) Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
- ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
- ØªÙ†Ø¨ÙŠÙ‡Ø§Øª ÙÙˆØ±ÙŠØ©
- Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ØªØµØ­ÙŠØ­

### 3. Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª

#### Ø£) ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†
- ØªØ­Ø¯ÙŠØ«Ø§Øª Ø¯ÙˆØ±ÙŠØ©
- Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø«ØºØ±Ø§Øª
- ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ù…Ø§Ù†

#### Ø¨) ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ù…ÙŠØ²Ø§Øª
- Ø¥Ø¶Ø§ÙØ© Ù…ÙŠØ²Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
- ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
- ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡

## Ø§Ù„Ø®Ù„Ø§ØµØ©

Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙŠÙ…Ø«Ù„ ØªØ·Ø¨ÙŠÙ‚Ø§Ù‹ Ù…ØªÙƒØ§Ù…Ù„Ø§Ù‹ Ù„ØªØ¹Ù„ÙŠÙ… ÙˆØªØµØ­ÙŠØ­ Ø§Ù„Ù†Ø·Ù‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. ÙŠØªÙ…ÙŠØ² Ø¨Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ÙˆØ§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ø¹Ø§Ù„ÙŠ ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ù…ØªØ§Ø². Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙŠØ¯Ø¹Ù… Ø§Ù„Ù„ØºØªÙŠÙ† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙˆÙŠÙˆÙØ± ØªØ¬Ø±Ø¨Ø© Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù…ØªØ§Ø²Ø© Ù…Ø¹ ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ø­Ø¯ÙŠØ«Ø©.

### Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:
1. **Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©**: Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
2. **Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ø¹Ø§Ù„ÙŠ**: Ø­Ù…Ø§ÙŠØ© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
3. **Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ù…ØªØ§Ø²**: ØªØ­Ø³ÙŠÙ† Ø´Ø§Ù…Ù„ Ù„Ù„Ø£Ø¯Ø§Ø¡
4. **Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„Ù†Ø´Ø±**: Ø§Ø³ØªØ®Ø¯Ø§Ù… Docker Ù„Ù„ØªØ´ØºÙŠÙ„
5. **Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„ØªÙˆØ³Ø¹**: Ø¨Ù†ÙŠØ© Ù…Ø±Ù†Ø© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ·ÙˆÙŠØ±

### Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ:
1. Ø¥Ø¶Ø§ÙØ© Ù„ØºØ§Øª Ø¬Ø¯ÙŠØ¯Ø©
2. ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
3. Ø¥Ø¶Ø§ÙØ© Ù…ÙŠØ²Ø§Øª ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©
4. ØªØ·ÙˆÙŠØ± ØªØ·Ø¨ÙŠÙ‚ Ù…ÙˆØ¨Ø§ÙŠÙ„
5. Ø¥Ø¶Ø§ÙØ© ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ØªÙ‚Ø¯Ù…

### 8. ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ TTS Ù…Ø®ØµØµ (Custom TTS Model Training)

#### Ø£) Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨

**1. Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:**
```python
"""
Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ TTS Ù…Ø®ØµØµ
"""
import os
import shutil
from pathlib import Path

class TTSDataPreparation:
    def __init__(self, base_dir="./custom_tts_data"):
        self.base_dir = Path(base_dir)
        self.setup_directory_structure()
    
    def setup_directory_structure(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©"""
        directories = [
            "raw_audio",           # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            "processed_audio",      # Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            "transcripts",          # Ù†ØµÙˆØµ Ø§Ù„Ù†Ø·Ù‚
            "metadata",            # Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©
            "validation",          # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚
            "test",                # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
            "models",              # Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©
            "logs",                # Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            "checkpoints"          # Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ­Ù‚Ù‚
        ]
        
        for dir_name in directories:
            dir_path = self.base_dir / dir_name
            dir_path.mkdir(parents=True, exist_ok=True)
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯: {dir_path}")
    
    def organize_audio_files(self, source_dir, target_format="wav"):
        """
        ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
        """
        source_path = Path(source_dir)
        target_dir = self.base_dir / "raw_audio"
        
        # Ø¯Ø¹Ù… Ø§Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
        supported_formats = ['.mp3', '.wav', '.flac', '.m4a', '.ogg']
        
        for audio_file in source_path.rglob("*"):
            if audio_file.suffix.lower() in supported_formats:
                # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ WAV Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
                if audio_file.suffix.lower() != '.wav':
                    converted_file = self.convert_to_wav(audio_file, target_dir)
                else:
                    converted_file = target_dir / audio_file.name
                    shutil.copy2(audio_file, converted_file)
                
                print(f"âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø©: {audio_file.name}")
        
        return target_dir
    
    def convert_to_wav(self, input_file, output_dir, sample_rate=22050):
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ WAV
        """
        import librosa
        import soundfile as sf
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª
        audio, sr = librosa.load(input_file, sr=sample_rate)
        
        # Ø­ÙØ¸ ÙƒÙ€ WAV
        output_file = output_dir / f"{input_file.stem}.wav"
        sf.write(output_file, audio, sample_rate)
        
        return output_file

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
data_prep = TTSDataPreparation("./my_custom_tts")
data_prep.organize_audio_files("./my_voice_samples")
```

**2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ù†Ø·Ù‚:**
```python
class TranscriptPreparation:
    def __init__(self, data_dir):
        self.data_dir = Path(data_dir)
        self.transcripts_dir = self.data_dir / "transcripts"
        self.metadata_dir = self.data_dir / "metadata"
    
    def create_transcript_file(self, audio_file, text, language="ar"):
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ù†ØµÙŠ Ù„Ù„Ù†Ø·Ù‚
        """
        transcript_file = self.transcripts_dir / f"{audio_file.stem}.txt"
        
        with open(transcript_file, 'w', encoding='utf-8') as f:
            f.write(text.strip())
        
        return transcript_file
    
    def create_metadata_file(self, audio_files, transcripts):
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
        """
        metadata_file = self.metadata_dir / "metadata.csv"
        
        with open(metadata_file, 'w', encoding='utf-8') as f:
            f.write("audio_file,text,language\n")
            
            for audio_file, text in zip(audio_files, transcripts):
                relative_path = audio_file.relative_to(self.data_dir / "processed_audio")
                f.write(f"{relative_path},{text},{language}\n")
        
        return metadata_file
    
    def validate_transcripts(self, audio_files, transcripts):
        """
        Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©
        """
        import librosa
        
        valid_pairs = []
        
        for audio_file, text in zip(audio_files, transcripts):
            try:
                # ÙØ­Øµ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
                audio, sr = librosa.load(audio_file, sr=None)
                duration = len(audio) / sr
                
                # ÙØ­Øµ Ø§Ù„Ù†Øµ
                if len(text.strip()) > 0 and duration > 0.5 and duration < 30:
                    valid_pairs.append((audio_file, text))
                else:
                    print(f"âš ï¸ ØªÙ… ØªØ¬Ø§Ù‡Ù„: {audio_file.name} - Ù…Ø¯Ø©: {duration:.2f}s")
                    
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ: {audio_file.name} - {e}")
        
        return valid_pairs

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
transcript_prep = TranscriptPreparation("./my_custom_tts")

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ØµÙˆØµ
audio_files = list(Path("./my_custom_tts/processed_audio").glob("*.wav"))
transcripts = [
    "Ù…Ø±Ø­Ø¨Ø§ ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ",
    "Ø£Ù†Ø§ Ø£ØªØ¹Ù„Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
    "Ù‡Ø°Ø§ ØªØ·Ø¨ÙŠÙ‚ Ø±Ø§Ø¦Ø¹",
    "Ø´ÙƒØ±Ø§ Ù„Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©"
]

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª Ø§Ù„Ù†ØµÙˆØµ
for audio_file, text in zip(audio_files, transcripts):
    transcript_prep.create_transcript_file(audio_file, text)

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©
metadata_file = transcript_prep.create_metadata_file(audio_files, transcripts)
```

#### Ø¨) Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ©

**1. ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª:**
```python
class AudioPreprocessor:
    def __init__(self, sample_rate=22050, target_duration=10):
        self.sample_rate = sample_rate
        self.target_duration = target_duration
    
    def preprocess_audio(self, input_file, output_file):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
        """
        import librosa
        import soundfile as sf
        import numpy as np
        from scipy import signal
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª
        audio, sr = librosa.load(input_file, sr=self.sample_rate)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
        audio_denoised = self.remove_noise(audio)
        
        # ØªØ·Ø¨ÙŠØ¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª
        audio_normalized = self.normalize_audio(audio_denoised)
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª
        audio_trimmed = self.trim_silence(audio_normalized)
        
        # Ø¶Ø¨Ø· Ø§Ù„Ù…Ø¯Ø©
        audio_padded = self.pad_or_trim(audio_trimmed)
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬
        sf.write(output_file, audio_padded, self.sample_rate)
        
        return output_file
    
    def remove_noise(self, audio, noise_reduce_level=0.1):
        """
        Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙ„ØªØ± Ù…Ø±Ø´Ø­
        """
        from scipy import signal
        
        # ØªØµÙ…ÙŠÙ… ÙÙ„ØªØ± Ù…Ø±Ø´Ø­
        nyquist = self.sample_rate / 2
        low = 80 / nyquist
        high = 8000 / nyquist
        
        b, a = signal.butter(4, [low, high], btype='band')
        filtered_audio = signal.filtfilt(b, a, audio)
        
        return filtered_audio
    
    def normalize_audio(self, audio, target_rms=0.1):
        """
        ØªØ·Ø¨ÙŠØ¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª
        """
        rms = np.sqrt(np.mean(audio**2))
        if rms > 0:
            normalized_audio = audio * (target_rms / rms)
            # Ù‚Øµ Ø§Ù„Ù‚Ù…Ù…
            normalized_audio = np.clip(normalized_audio, -0.95, 0.95)
            return normalized_audio
        return audio
    
    def trim_silence(self, audio, threshold=0.01):
        """
        Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª Ù…Ù† Ø¨Ø¯Ø§ÙŠØ© ÙˆÙ†Ù‡Ø§ÙŠØ© Ø§Ù„Ù…Ù„Ù
        """
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
        start_idx = np.where(np.abs(audio) > threshold)[0]
        if len(start_idx) > 0:
            audio = audio[start_idx[0]:]
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙ…Øª Ù…Ù† Ø§Ù„Ù†Ù‡Ø§ÙŠØ©
        end_idx = np.where(np.abs(audio) > threshold)[0]
        if len(end_idx) > 0:
            audio = audio[:end_idx[-1] + 1]
        
        return audio
    
    def pad_or_trim(self, audio):
        """
        Ø¶Ø¨Ø· Ù…Ø¯Ø© Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        """
        target_length = self.sample_rate * self.target_duration
        
        if len(audio) > target_length:
            # ØªÙ‚ØµÙŠØ± Ø§Ù„ØµÙˆØª
            audio = audio[:target_length]
        elif len(audio) < target_length:
            # Ø¥Ø·Ø§Ù„Ø© Ø§Ù„ØµÙˆØª Ø¨Ø§Ù„ØµÙ…Øª
            padding_length = target_length - len(audio)
            padding = np.zeros(padding_length)
            audio = np.concatenate([audio, padding])
        
        return audio

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
preprocessor = AudioPreprocessor(sample_rate=22050, target_duration=10)

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ©
raw_audio_dir = Path("./my_custom_tts/raw_audio")
processed_audio_dir = Path("./my_custom_tts/processed_audio")

for audio_file in raw_audio_dir.glob("*.wav"):
    output_file = processed_audio_dir / audio_file.name
    preprocessor.preprocess_audio(audio_file, output_file)
    print(f"âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø©: {audio_file.name}")
```

**2. ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:**
```python
class DataSplitter:
    def __init__(self, data_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):
        self.data_dir = Path(data_dir)
        self.train_ratio = train_ratio
        self.val_ratio = val_ratio
        self.test_ratio = test_ratio
    
    def split_data(self, metadata_file):
        """
        ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ ÙˆØªØ­Ù‚Ù‚ ÙˆØ§Ø®ØªØ¨Ø§Ø±
        """
        import pandas as pd
        from sklearn.model_selection import train_test_split
        
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©
        df = pd.read_csv(metadata_file)
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        train_data, temp_data = train_test_split(
            df, test_size=(1 - self.train_ratio), random_state=42
        )
        
        val_data, test_data = train_test_split(
            temp_data, test_size=self.test_ratio/(self.val_ratio + self.test_ratio), 
            random_state=42
        )
        
        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‚Ø³Ù…Ø©
        train_file = self.data_dir / "metadata" / "train.csv"
        val_file = self.data_dir / "metadata" / "val.csv"
        test_file = self.data_dir / "metadata" / "test.csv"
        
        train_data.to_csv(train_file, index=False)
        val_data.to_csv(val_file, index=False)
        test_data.to_csv(test_file, index=False)
        
        print(f"ğŸ“Š ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
        print(f"   Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {len(train_data)} Ø¹ÙŠÙ†Ø©")
        print(f"   Ø§Ù„ØªØ­Ù‚Ù‚: {len(val_data)} Ø¹ÙŠÙ†Ø©")
        print(f"   Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {len(test_data)} Ø¹ÙŠÙ†Ø©")
        
        return train_file, val_file, test_file

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
splitter = DataSplitter("./my_custom_tts")
train_file, val_file, test_file = splitter.split_data("./my_custom_tts/metadata/metadata.csv")
```

#### Ø¬) Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨

**1. ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**
```python
class TTSModelConfig:
    def __init__(self, model_type="tacotron2"):
        self.model_type = model_type
        self.config = self.get_default_config()
    
    def get_default_config(self):
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
        """
        if self.model_type == "tacotron2":
            return {
                "model": {
                    "encoder": {
                        "encoder_embedding_dim": 512,
                        "encoder_n_convolutions": 3,
                        "encoder_kernel_size": 5
                    },
                    "decoder": {
                        "decoder_rnn_dim": 1024,
                        "decoder_layer_norm": True,
                        "decoder_dropout": 0.1
                    },
                    "postnet": {
                        "postnet_embedding_dim": 512,
                        "postnet_kernel_size": 5,
                        "postnet_n_convolutions": 5
                    }
                },
                "training": {
                    "batch_size": 32,
                    "learning_rate": 0.001,
                    "epochs": 1000,
                    "gradient_clip_thresh": 1.0,
                    "weight_decay": 1e-6
                },
                "audio": {
                    "sample_rate": 22050,
                    "hop_length": 256,
                    "win_length": 1024,
                    "n_mel_channels": 80,
                    "mel_fmin": 0.0,
                    "mel_fmax": 8000.0
                }
            }
        elif self.model_type == "fastspeech2":
            return {
                "model": {
                    "encoder": {
                        "encoder_dim": 256,
                        "encoder_n_layer": 4,
                        "encoder_head": 2
                    },
                    "decoder": {
                        "decoder_dim": 256,
                        "decoder_n_layer": 4,
                        "decoder_head": 2
                    }
                },
                "training": {
                    "batch_size": 16,
                    "learning_rate": 0.0001,
                    "epochs": 1000
                }
            }
        
        return {}
    
    def save_config(self, config_path):
        """
        Ø­ÙØ¸ ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        """
        import json
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙƒÙˆÙŠÙ† ÙÙŠ: {config_path}")
    
    def load_config(self, config_path):
        """
        ØªØ­Ù…ÙŠÙ„ ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        """
        import json
        
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
        
        return self.config

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
config = TTSModelConfig("tacotron2")
config.save_config("./my_custom_tts/models/config.json")
```

**2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨:**
```python
class TTSTrainer:
    def __init__(self, data_dir, model_config, output_dir):
        self.data_dir = Path(data_dir)
        self.config = model_config
        self.output_dir = Path(output_dir)
        self.setup_training_environment()
    
    def setup_training_environment(self):
        """
        Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        """
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        (self.output_dir / "checkpoints").mkdir(parents=True, exist_ok=True)
        (self.output_dir / "logs").mkdir(parents=True, exist_ok=True)
        (self.output_dir / "models").mkdir(parents=True, exist_ok=True)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ TensorBoard
        self.log_dir = self.output_dir / "logs"
        
        print("âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
    
    def prepare_dataset(self, metadata_file):
        """
        Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨
        """
        import pandas as pd
        
        df = pd.read_csv(metadata_file)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØ§Ù„Ù†ØµÙˆØµ
        audio_files = []
        texts = []
        
        for _, row in df.iterrows():
            audio_path = self.data_dir / "processed_audio" / row['audio_file']
            if audio_path.exists():
                audio_files.append(str(audio_path))
                texts.append(row['text'])
        
        return audio_files, texts
    
    def create_vocabulary(self, texts):
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØ±Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        """
        # ØªØ¬Ù…ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
        all_chars = set()
        for text in texts:
            all_chars.update(text)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØ±Ø¯Ø§Øª Ù…Ø±ØªØ¨Ø©
        vocab = ['<pad>', '<unk>', '<sos>', '<eos>'] + sorted(list(all_chars))
        
        # Ø­ÙØ¸ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
        vocab_file = self.output_dir / "vocab.txt"
        with open(vocab_file, 'w', encoding='utf-8') as f:
            for char in vocab:
                f.write(char + '\n')
        
        return vocab, vocab_file
    
    def train_model(self, train_file, val_file, resume_from=None):
        """
        ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        """
        print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        train_audio, train_texts = self.prepare_dataset(train_file)
        val_audio, val_texts = self.prepare_dataset(val_file)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
        vocab, vocab_file = self.create_vocabulary(train_texts + val_texts)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model = self.setup_model(vocab)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        trainer = self.setup_trainer(model)
        
        # Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        trainer.train(
            train_audio=train_audio,
            train_texts=train_texts,
            val_audio=val_audio,
            val_texts=val_texts,
            resume_from=resume_from
        )
        
        print("âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
    
    def setup_model(self, vocab):
        """
        Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        """
        # Ù‡Ù†Ø§ ÙŠØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…Ø®ØªØ§Ø±
        # ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… TTS Ø£Ùˆ Coqui TTS Ø£Ùˆ Ø£ÙŠ Ù…ÙƒØªØ¨Ø© Ø£Ø®Ø±Ù‰
        pass
    
    def setup_trainer(self, model):
        """
        Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¯Ø±Ø¨
        """
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø¹ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        pass

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
trainer = TTSTrainer(
    data_dir="./my_custom_tts",
    model_config=config.config,
    output_dir="./my_custom_tts/models"
)

trainer.train_model(
    train_file="./my_custom_tts/metadata/train.csv",
    val_file="./my_custom_tts/metadata/val.csv"
)
```

#### Ø¯) ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†

**1. ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**
```python
class TTSEvaluator:
    def __init__(self, model_path, config_path):
        self.model_path = Path(model_path)
        self.config = self.load_config(config_path)
        self.model = self.load_model()
    
    def evaluate_model(self, test_file):
        """
        ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        """
        import pandas as pd
        from scipy.stats import pearsonr
        import numpy as np
        
        df = pd.read_csv(test_file)
        results = []
        
        for _, row in df.iterrows():
            # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù…
            generated_audio = self.generate_speech(row['text'])
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ
            reference_audio = self.load_audio(row['audio_file'])
            
            # Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø¬ÙˆØ¯Ø©
            metrics = self.calculate_quality_metrics(generated_audio, reference_audio)
            results.append(metrics)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª
        avg_metrics = self.calculate_average_metrics(results)
        
        return avg_metrics
    
    def calculate_quality_metrics(self, generated_audio, reference_audio):
        """
        Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª
        """
        import librosa
        from scipy.stats import pearsonr
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…ÙŠØ²Ø§Øª Mel-spectrogram
        gen_mel = librosa.feature.melspectrogram(
            y=generated_audio, 
            sr=self.config['audio']['sample_rate']
        )
        ref_mel = librosa.feature.melspectrogram(
            y=reference_audio, 
            sr=self.config['audio']['sample_rate']
        )
        
        # Ø­Ø³Ø§Ø¨ MSE
        mse = np.mean((gen_mel - ref_mel) ** 2)
        
        # Ø­Ø³Ø§Ø¨ MAE
        mae = np.mean(np.abs(gen_mel - ref_mel))
        
        # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·
        correlation = pearsonr(gen_mel.flatten(), ref_mel.flatten())[0]
        
        return {
            'mse': mse,
            'mae': mae,
            'correlation': correlation
        }
    
    def calculate_average_metrics(self, results):
        """
        Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
        """
        avg_metrics = {}
        for key in results[0].keys():
            values = [r[key] for r in results]
            avg_metrics[key] = np.mean(values)
            avg_metrics[f"{key}_std"] = np.std(values)
        
        return avg_metrics
    
    def generate_speech(self, text):
        """
        ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù…Ù† Ø§Ù„Ù†Øµ
        """
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù…
        pass
    
    def load_audio(self, audio_file):
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ
        """
        import librosa
        audio, _ = librosa.load(audio_file, sr=self.config['audio']['sample_rate'])
        return audio

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
evaluator = TTSEvaluator(
    model_path="./my_custom_tts/models/best_model.pth",
    config_path="./my_custom_tts/models/config.json"
)

metrics = evaluator.evaluate_model("./my_custom_tts/metadata/test.csv")
print("ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:")
for metric, value in metrics.items():
    print(f"   {metric}: {value:.4f}")
```

**2. ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**
```python
class TTSOptimizer:
    def __init__(self, model_path, config_path):
        self.model_path = Path(model_path)
        self.config = self.load_config(config_path)
    
    def hyperparameter_optimization(self, train_file, val_file):
        """
        ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ÙØ§Ø¦Ù‚Ø©
        """
        import optuna
        
        def objective(trial):
            # Ø§Ù‚ØªØ±Ø§Ø­ Ù‚ÙŠÙ… Ù„Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
            learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
            batch_size = trial.suggest_categorical('batch_size', [8, 16, 32, 64])
            encoder_dim = trial.suggest_categorical('encoder_dim', [256, 512, 1024])
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙƒÙˆÙŠÙ†
            self.config['training']['learning_rate'] = learning_rate
            self.config['training']['batch_size'] = batch_size
            self.config['model']['encoder']['encoder_embedding_dim'] = encoder_dim
            
            # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            trainer = TTSTrainer(
                data_dir="./my_custom_tts",
                model_config=self.config,
                output_dir=f"./my_custom_tts/optimization/trial_{trial.number}"
            )
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            evaluator = TTSEvaluator(
                model_path=trainer.output_dir / "best_model.pth",
                config_path=trainer.output_dir / "config.json"
            )
            
            metrics = evaluator.evaluate_model(val_file)
            
            # Ø¥Ø±Ø¬Ø§Ø¹ Ù‚ÙŠÙ…Ø© Ø§Ù„Ù‡Ø¯Ù (MSE Ø£Ù‚Ù„ = Ø£ÙØ¶Ù„)
            return metrics['mse']
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¯Ø±Ø§Ø³Ø© Optuna
        study = optuna.create_study(direction='minimize')
        study.optimize(objective, n_trials=20)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª
        best_params = study.best_params
        print("ğŸ¯ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:")
        for param, value in best_params.items():
            print(f"   {param}: {value}")
        
        return best_params
    
    def model_ensemble(self, model_paths, weights=None):
        """
        Ø¯Ù…Ø¬ Ø¹Ø¯Ø© Ù†Ù…Ø§Ø°Ø¬ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
        """
        if weights is None:
            weights = [1.0 / len(model_paths)] * len(model_paths)
        
        models = []
        for model_path in model_paths:
            model = self.load_model(model_path)
            models.append(model)
        
        def ensemble_generate(text):
            outputs = []
            for model, weight in zip(models, weights):
                output = model.generate(text)
                outputs.append(output * weight)
            
            # Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª
            ensemble_output = sum(outputs)
            return ensemble_output
        
        return ensemble_generate

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
optimizer = TTSOptimizer(
    model_path="./my_custom_tts/models/best_model.pth",
    config_path="./my_custom_tts/models/config.json"
)

# ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ÙØ§Ø¦Ù‚Ø©
best_params = optimizer.hyperparameter_optimization(
    train_file="./my_custom_tts/metadata/train.csv",
    val_file="./my_custom_tts/metadata/val.csv"
)

# Ø¯Ù…Ø¬ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
model_paths = [
    "./my_custom_tts/models/model_1.pth",
    "./my_custom_tts/models/model_2.pth",
    "./my_custom_tts/models/model_3.pth"
]

ensemble_model = optimizer.model_ensemble(model_paths)
```

#### Ù‡Ù€) Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨

**1. ØªØ­Ù…ÙŠÙ„ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**
```python
class CustomTTSInference:
    def __init__(self, model_path, config_path, vocab_path):
        self.model_path = Path(model_path)
        self.config = self.load_config(config_path)
        self.vocab = self.load_vocabulary(vocab_path)
        self.model = self.load_model()
    
    def load_vocabulary(self, vocab_path):
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
        """
        with open(vocab_path, 'r', encoding='utf-8') as f:
            vocab = [line.strip() for line in f.readlines()]
        return vocab
    
    def text_to_sequence(self, text):
        """
        ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ Ø£Ø±Ù‚Ø§Ù…
        """
        char_to_id = {char: i for i, char in enumerate(self.vocab)}
        sequence = [char_to_id.get(char, char_to_id['<unk>']) for char in text]
        sequence = [char_to_id['<sos>']] + sequence + [char_to_id['<eos>']]
        return sequence
    
    def generate_speech(self, text, output_path=None):
        """
        ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù…Ù† Ø§Ù„Ù†Øµ
        """
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„
        sequence = self.text_to_sequence(text)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù…
        with torch.no_grad():
            audio = self.model.inference(sequence)
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
        if output_path:
            import soundfile as sf
            sf.write(output_path, audio, self.config['audio']['sample_rate'])
        
        return audio
    
    def batch_generate(self, texts, output_dir):
        """
        ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù„Ø¹Ø¯Ø© Ù†ØµÙˆØµ Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©
        """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        results = []
        for i, text in enumerate(texts):
            output_path = output_dir / f"generated_{i:03d}.wav"
            audio = self.generate_speech(text, output_path)
            results.append({
                'text': text,
                'audio': audio,
                'file_path': output_path
            })
        
        return results

# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
custom_tts = CustomTTSInference(
    model_path="./my_custom_tts/models/best_model.pth",
    config_path="./my_custom_tts/models/config.json",
    vocab_path="./my_custom_tts/models/vocab.txt"
)

# ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù„ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©
audio = custom_tts.generate_speech("Ù…Ø±Ø­Ø¨Ø§ ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ", "output.wav")

# ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù„Ø¹Ø¯Ø© ÙƒÙ„Ù…Ø§Øª
texts = [
    "Ø£Ù†Ø§ Ø£ØªØ¹Ù„Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
    "Ù‡Ø°Ø§ ØªØ·Ø¨ÙŠÙ‚ Ø±Ø§Ø¦Ø¹",
    "Ø´ÙƒØ±Ø§ Ù„Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©"
]

results = custom_tts.batch_generate(texts, "./generated_audio")
```

**2. ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®ØµØµ:**
```python
from flask import Flask, request, jsonify, send_file
import io

app = Flask(__name__)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®ØµØµ
custom_tts = CustomTTSInference(
    model_path="./my_custom_tts/models/best_model.pth",
    config_path="./my_custom_tts/models/config.json",
    vocab_path="./my_custom_tts/models/vocab.txt"
)

@app.route('/api/custom-tts/generate', methods=['POST'])
def generate_custom_speech():
    """
    ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø®ØµØµ
    """
    try:
        data = request.get_json()
        text = data.get('text', '')
        language = data.get('language', 'ar')
        
        if not text:
            return jsonify({'error': 'Ø§Ù„Ù†Øµ Ù…Ø·Ù„ÙˆØ¨'}), 400
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù…
        audio = custom_tts.generate_speech(text)
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù…Ù„Ù ØµÙˆØªÙŠ
        import soundfile as sf
        buffer = io.BytesIO()
        sf.write(buffer, audio, custom_tts.config['audio']['sample_rate'], format='WAV')
        buffer.seek(0)
        
        return send_file(
            buffer,
            mimetype='audio/wav',
            as_attachment=True,
            download_name=f'custom_tts_{text[:10]}.wav'
        )
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/custom-tts/batch-generate', methods=['POST'])
def batch_generate_custom_speech():
    """
    ØªÙˆÙ„ÙŠØ¯ ÙƒÙ„Ø§Ù… Ù„Ø¹Ø¯Ø© Ù†ØµÙˆØµ Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©
    """
    try:
        data = request.get_json()
        texts = data.get('texts', [])
        language = data.get('language', 'ar')
        
        if not texts:
            return jsonify({'error': 'Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ Ù…Ø·Ù„ÙˆØ¨Ø©'}), 400
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ÙƒÙ„Ø§Ù…
        results = custom_tts.batch_generate(texts, "./temp_audio")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ZIP
        import zipfile
        import os
        
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w') as zip_file:
            for result in results:
                zip_file.write(result['file_path'], result['file_path'].name)
        
        zip_buffer.seek(0)
        
        return send_file(
            zip_buffer,
            mimetype='application/zip',
            as_attachment=True,
            download_name='custom_tts_batch.zip'
        )
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True, port=5001)
```

Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… ÙŠÙˆÙØ± Ø¯Ù„ÙŠÙ„Ø§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ TTS Ù…Ø®ØµØµ Ù…Ù† Ø§Ù„ØµÙØ±ØŒ Ø¨Ø¯Ø¡Ø§Ù‹ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù†ØªÙ‡Ø§Ø¡Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.
